## Batch Learning e Online Learning em Redes Neurais

<img src="C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240816101829816.png" alt="image-20240816101829816" style="zoom:80%;" />

O treinamento de redes neurais Ã© um processo fundamental na aprendizagem de mÃ¡quina, e duas abordagens principais se destacam: batch learning (aprendizagem em lote) e online learning (aprendizagem online). Este resumo explorarÃ¡ em profundidade essas duas tÃ©cnicas, suas implementaÃ§Ãµes no contexto do algoritmo de retropropagaÃ§Ã£o, vantagens, desvantagens e aplicaÃ§Ãµes prÃ¡ticas [1].

### Conceitos Fundamentais

| Conceito            | ExplicaÃ§Ã£o                                                   |
| ------------------- | ------------------------------------------------------------ |
| **Batch Learning**  | MÃ©todo de treinamento onde os parÃ¢metros da rede sÃ£o atualizados apÃ³s processar todo o conjunto de dados de treinamento [1]. |
| **Online Learning** | TÃ©cnica de treinamento onde os parÃ¢metros sÃ£o atualizados apÃ³s processar cada exemplo individual do conjunto de dados [1]. |
| **RetropropagaÃ§Ã£o** | Algoritmo fundamental para o treinamento de redes neurais, que calcula o gradiente da funÃ§Ã£o de erro em relaÃ§Ã£o aos pesos da rede [2]. |

> âœ”ï¸ **Ponto de Destaque**: A escolha entre batch learning e online learning pode impactar significativamente a velocidade de convergÃªncia e a qualidade do modelo final.

### Batch Learning

![image-20240816102424437](C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240816102424437.png)

O batch learning, tambÃ©m conhecido como aprendizagem em lote, Ã© uma abordagem onde a rede neural processa todo o conjunto de dados de treinamento antes de realizar uma atualizaÃ§Ã£o dos pesos [1]. 

#### ImplementaÃ§Ã£o MatemÃ¡tica

Para um conjunto de treinamento com N observaÃ§Ãµes, a atualizaÃ§Ã£o dos pesos no batch learning Ã© dada por:

$$
\beta_{km}^{(r+1)} = \beta_{km}^{(r)} - \gamma_r \sum_{i=1}^N \frac{\partial R_i}{\partial \beta_{km}^{(r)}}
$$

$$
\alpha_{ml}^{(r+1)} = \alpha_{ml}^{(r)} - \gamma_r \sum_{i=1}^N \frac{\partial R_i}{\partial \alpha_{ml}^{(r)}}
$$

Onde:
- $\beta_{km}$ e $\alpha_{ml}$ sÃ£o os pesos da rede
- $r$ Ã© o nÃºmero da iteraÃ§Ã£o (Ã©poca)
- $\gamma_r$ Ã© a taxa de aprendizagem
- $R_i$ Ã© a funÃ§Ã£o de erro para a i-Ã©sima observaÃ§Ã£o [3]

#### ğŸ‘Vantagens
* Estimativas de gradiente mais estÃ¡veis
* Potencial para paralelizaÃ§Ã£o eficiente

#### ğŸ‘Desvantagens
* Requer mais memÃ³ria para armazenar todo o conjunto de dados
* Pode ser lento para conjuntos de dados muito grandes

#### [QuestÃµes TÃ©cnicas/TeÃ³ricas]

1. Como o tamanho do lote afeta a convergÃªncia do algoritmo de batch learning?
2. Em que situaÃ§Ãµes o batch learning pode ser preferÃ­vel ao online learning?

### Online Learning

O online learning atualiza os pesos da rede apÃ³s processar cada exemplo individual do conjunto de dados [1]. Esta abordagem Ã© particularmente Ãºtil para conjuntos de dados muito grandes ou streams de dados contÃ­nuos.

#### ImplementaÃ§Ã£o MatemÃ¡tica

No online learning, as atualizaÃ§Ãµes de peso ocorrem para cada observaÃ§Ã£o:

$$
\beta_{km}^{(r+1)} = \beta_{km}^{(r)} - \gamma_r \frac{\partial R_i}{\partial \beta_{km}^{(r)}}
$$

$$
\alpha_{ml}^{(r+1)} = \alpha_{ml}^{(r)} - \gamma_r \frac{\partial R_i}{\partial \alpha_{ml}^{(r)}}
$$

Onde $i$ representa o Ã­ndice da observaÃ§Ã£o atual [3].

> âš ï¸ **Nota Importante**: A taxa de aprendizagem $\gamma_r$ no online learning deve geralmente diminuir com o tempo para garantir a convergÃªncia.

#### Taxa de Aprendizagem Adaptativa

Para garantir a convergÃªncia no online learning, a taxa de aprendizagem deve satisfazer as seguintes condiÃ§Ãµes:

1. $\gamma_r \rightarrow 0$ conforme $r \rightarrow \infty$
2. $\sum_r \gamma_r = \infty$
3. $\sum_r \gamma_r^2 < \infty$

Uma escolha comum que satisfaz essas condiÃ§Ãµes Ã© $\gamma_r = \frac{1}{r}$ [4].

#### ğŸ‘Vantagens
* AdaptaÃ§Ã£o rÃ¡pida a novos dados
* Menor requisito de memÃ³ria

#### ğŸ‘Desvantagens
* AtualizaÃ§Ãµes de peso mais ruidosas
* Pode ser mais suscetÃ­vel a mÃ­nimos locais

#### [QuestÃµes TÃ©cnicas/TeÃ³ricas]

1. Como vocÃª implementaria uma estratÃ©gia de decaimento da taxa de aprendizagem em online learning?
2. Quais sÃ£o as implicaÃ§Ãµes do online learning para a estacionariedade dos dados?

### ComparaÃ§Ã£o entre Batch e Online Learning

| Aspecto                         | Batch Learning | Online Learning |
| ------------------------------- | -------------- | --------------- |
| Uso de MemÃ³ria                  | Alto           | Baixo           |
| Velocidade de AdaptaÃ§Ã£o         | Lenta          | RÃ¡pida          |
| Estabilidade do Gradiente       | Alta           | Baixa           |
| AdequaÃ§Ã£o para Grandes Datasets | Menor          | Maior           |

### ImplementaÃ§Ã£o PrÃ¡tica

Aqui estÃ¡ um exemplo simplificado de como implementar batch e online learning em Python usando NumPy:

````python
import numpy as np

class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.weights1 = np.random.randn(input_size, hidden_size)
        self.weights2 = np.random.randn(hidden_size, output_size)
    
    def forward(self, X):
        self.z = np.dot(X, self.weights1)
        self.z2 = self.sigmoid(self.z)
        self.z3 = np.dot(self.z2, self.weights2)
        return self.sigmoid(self.z3)
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def backward(self, X, y, output):
        self.output_error = y - output
        self.output_delta = self.output_error * self.sigmoid_derivative(output)
        
        self.z2_error = self.output_delta.dot(self.weights2.T)
        self.z2_delta = self.z2_error * self.sigmoid_derivative(self.z2)
        
        self.weights2 += self.z2.T.dot(self.output_delta)
        self.weights1 += X.T.dot(self.z2_delta)
    
    def train_batch(self, X, y, epochs):
        for _ in range(epochs):
            output = self.forward(X)
            self.backward(X, y, output)
    
    def train_online(self, X, y, epochs):
        for _ in range(epochs):
            for i in range(X.shape[0]):
                output = self.forward(X[i:i+1])
                self.backward(X[i:i+1], y[i:i+1], output)
````

Este exemplo demonstra a implementaÃ§Ã£o bÃ¡sica de uma rede neural com uma camada oculta, utilizando tanto batch learning quanto online learning [5].

### ConclusÃ£o

Batch learning e online learning sÃ£o duas abordagens fundamentais para o treinamento de redes neurais, cada uma com suas prÃ³prias vantagens e desvantagens. A escolha entre elas depende de fatores como o tamanho do conjunto de dados, requisitos de memÃ³ria, velocidade de adaptaÃ§Ã£o necessÃ¡ria e a natureza do problema em questÃ£o. Compreender as nuances de cada mÃ©todo Ã© crucial para desenvolver modelos de aprendizagem de mÃ¡quina eficientes e eficazes [1][3][4].

### QuestÃµes AvanÃ§adas

1. Como vocÃª projetaria um sistema hÃ­brido que combina batch e online learning para otimizar o treinamento em um cenÃ¡rio de streaming de dados?

2. Discuta as implicaÃ§Ãµes teÃ³ricas e prÃ¡ticas de usar mini-batch learning como um meio-termo entre batch e online learning. Como isso afeta a convergÃªncia e a eficiÃªncia computacional?

3. Em um cenÃ¡rio de aprendizado por reforÃ§o, como vocÃª adaptaria os princÃ­pios de online learning para lidar com a natureza sequencial e potencialmente nÃ£o-estacionÃ¡ria do ambiente?

### ReferÃªncias

[1] "The updates in (11.13) are a kind of batch learning, with the parameter updates being a sum over all of the training cases. Learning can also be carried out onlineâ€”processing each observation one at a time, updating the gradient after each training case, and cycling through the training cases many times." (Trecho de ESL II)

[2] "The generic approach to minimizing R(Î¸) is by gradient descent, called back-propagation in this setting. Because of the compositional form of the model, the gradient can be easily derived using the chain rule for differentiation." (Trecho de ESL II)

[3] "Given these derivatives, a gradient descent update at the (r + 1)st iteration has the form
Î²(r+1)km = Î²(r)km âˆ’ Î³r âˆ‘Ni=1 âˆ‚Ri/âˆ‚Î²(r)km,
Î±(r+1)ml = Î±(r)ml âˆ’ Î³r âˆ‘Ni=1 âˆ‚Ri/âˆ‚Î±(r)ml,
where Î³r is the learning rate, discussed below." (Trecho de ESL II)

[4] "With online learning Î³r should decrease to zero as the iteration r â†’ âˆ. This learning is a form of stochastic approximation (Robbins and Munro, 1951); results in this field ensure convergence if Î³r â†’ 0, âˆ‘r Î³r = âˆ, and âˆ‘r Î³2r < âˆ (satisfied, for example, by Î³r = 1/r)." (Trecho de ESL II)

[5] "Back-propagation can be very slow, and for that reason is usually not the method of choice. Second-order techniques such as Newton's method are not attractive here, because the second derivative matrix of R (the Hessian) can be very large." (Trecho de ESL II)