## Algoritmo de RetropropagaÃ§Ã£o (Back-propagation)

![image-20240816100749672](C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240816100749672.png)

O algoritmo de retropropagaÃ§Ã£o Ã© uma tÃ©cnica fundamental para o treinamento de redes neurais artificiais, permitindo a otimizaÃ§Ã£o eficiente dos pesos da rede atravÃ©s do cÃ¡lculo do gradiente da funÃ§Ã£o de erro em relaÃ§Ã£o aos parÃ¢metros do modelo.

### Conceitos Fundamentais

| Conceito                  | ExplicaÃ§Ã£o                                                   |
| ------------------------- | ------------------------------------------------------------ |
| **FunÃ§Ã£o de Erro**        | Medida quantitativa da diferenÃ§a entre as saÃ­das previstas pela rede e os valores reais desejados. Comumente utiliza-se o erro quadrÃ¡tico mÃ©dio. [9] |
| **Gradiente Descendente** | MÃ©todo de otimizaÃ§Ã£o que ajusta iterativamente os parÃ¢metros na direÃ§Ã£o oposta ao gradiente da funÃ§Ã£o de erro, buscando minimizÃ¡-la. [9] |
| **Regra da Cadeia**       | PrincÃ­pio matemÃ¡tico que permite calcular as derivadas parciais de funÃ§Ãµes compostas, essencial para a propagaÃ§Ã£o do erro atravÃ©s das camadas da rede. [12] |

> âš ï¸ **Nota Importante**: A eficÃ¡cia do algoritmo de retropropagaÃ§Ã£o depende crucialmente da escolha adequada da taxa de aprendizado e da inicializaÃ§Ã£o dos pesos da rede.

### Funcionamento do Algoritmo de RetropropagaÃ§Ã£o

O algoritmo de retropropagaÃ§Ã£o opera em duas fases principais: a propagaÃ§Ã£o direta (forward pass) e a retropropagaÃ§Ã£o (backward pass) [9].

1. **PropagaÃ§Ã£o Direta**:
   - As entradas sÃ£o propagadas atravÃ©s da rede, camada por camada.
   - Cada neurÃ´nio calcula sua ativaÃ§Ã£o baseada nas entradas ponderadas e na funÃ§Ã£o de ativaÃ§Ã£o.
   - A saÃ­da final da rede Ã© comparada com o valor desejado para calcular o erro.

2. **RetropropagaÃ§Ã£o**:
   - O erro Ã© propagado de volta atravÃ©s da rede.
   - Os gradientes sÃ£o calculados para cada parÃ¢metro usando a regra da cadeia.
   - Os pesos sÃ£o atualizados na direÃ§Ã£o oposta ao gradiente.

#### FormalizaÃ§Ã£o MatemÃ¡tica

Para uma rede neural com uma camada oculta, podemos expressar o processo matematicamente [12]:

Seja $z_m = \sigma(\alpha_{0m} + \alpha_m^T X)$ a ativaÃ§Ã£o da m-Ã©sima unidade oculta, onde $\sigma$ Ã© a funÃ§Ã£o de ativaÃ§Ã£o (comumente sigmÃ³ide). A saÃ­da da rede para a k-Ã©sima classe Ã© dada por:

$$
f_k(X) = g_k(\beta_{0k} + \beta_k^T Z)
$$

onde $Z = (z_1, z_2, ..., z_M)$ e $g_k$ Ã© a funÃ§Ã£o de ativaÃ§Ã£o da camada de saÃ­da.

O erro quadrÃ¡tico para uma Ãºnica observaÃ§Ã£o Ã©:

$$
R_i = \sum_{k=1}^K (y_{ik} - f_k(x_i))^2
$$

As derivadas parciais em relaÃ§Ã£o aos parÃ¢metros sÃ£o [12]:

$$
\frac{\partial R_i}{\partial \beta_{km}} = -2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i)z_{mi}
$$

$$
\frac{\partial R_i}{\partial \alpha_{m\ell}} = -\sum_{k=1}^K 2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i)\beta_{km}\sigma'(\alpha_m^T x_i)x_{i\ell}
$$

> âœ”ï¸ **Ponto de Destaque**: A eficiÃªncia computacional do algoritmo de retropropagaÃ§Ã£o vem da sua capacidade de reutilizar cÃ¡lculos intermediÃ¡rios, reduzindo significativamente o nÃºmero de operaÃ§Ãµes necessÃ¡rias.

### 1. Estrutura da Rede

Vamos comeÃ§ar definindo a estrutura bÃ¡sica da rede neural:

- Camada de entrada: $X = (x_1, x_2, ..., x_p)$, onde $p$ Ã© o nÃºmero de caracterÃ­sticas de entrada.
- Camada oculta: $M$ unidades ocultas.
- Camada de saÃ­da: $K$ unidades de saÃ­da (uma para cada classe em problemas de classificaÃ§Ã£o).

### 2. PropagaÃ§Ã£o Forward

#### 2.1 CÃ¡lculo das AtivaÃ§Ãµes da Camada Oculta

Para cada unidade oculta $m = 1, 2, ..., M$, calculamos sua ativaÃ§Ã£o $z_m$ da seguinte forma [12]:

$$ z_m = \sigma(\alpha_{0m} + \alpha_m^T X) $$

Onde:
- $\alpha_{0m}$ Ã© o termo de viÃ©s (bias) para a m-Ã©sima unidade oculta.
- $\alpha_m = (\alpha_{m1}, \alpha_{m2}, ..., \alpha_{mp})$ Ã© o vetor de pesos conectando a entrada Ã  m-Ã©sima unidade oculta.
- $\sigma$ Ã© a funÃ§Ã£o de ativaÃ§Ã£o, geralmente a funÃ§Ã£o sigmÃ³ide: $\sigma(v) = \frac{1}{1 + e^{-v}}$

> âœ”ï¸ **Ponto de Destaque**: A funÃ§Ã£o sigmÃ³ide introduz nÃ£o-linearidade na rede, permitindo que ela aprenda relaÃ§Ãµes complexas nos dados.

#### 2.2 CÃ¡lculo das SaÃ­das

Para cada unidade de saÃ­da $k = 1, 2, ..., K$, calculamos sua saÃ­da $f_k(X)$ como [12]:

$$ f_k(X) = g_k(\beta_{0k} + \beta_k^T Z) $$

Onde:
- $Z = (z_1, z_2, ..., z_M)$ Ã© o vetor de ativaÃ§Ãµes da camada oculta.
- $\beta_{0k}$ Ã© o termo de viÃ©s para a k-Ã©sima unidade de saÃ­da.
- $\beta_k = (\beta_{k1}, \beta_{k2}, ..., \beta_{kM})$ Ã© o vetor de pesos conectando a camada oculta Ã  k-Ã©sima unidade de saÃ­da.
- $g_k$ Ã© a funÃ§Ã£o de ativaÃ§Ã£o da camada de saÃ­da, que pode variar dependendo do problema:
  - Para regressÃ£o: $g_k(t) = t$ (funÃ§Ã£o identidade)
  - Para classificaÃ§Ã£o binÃ¡ria: $g_k(t) = \sigma(t)$ (sigmÃ³ide)
  - Para classificaÃ§Ã£o multiclasse: $g_k(t) = \frac{e^t}{\sum_{j=1}^K e^{t_j}}$ (softmax)

### 3. CÃ¡lculo do Erro

Para uma Ãºnica observaÃ§Ã£o $i$, o erro quadrÃ¡tico Ã© definido como [12]:

$$ R_i = \sum_{k=1}^K (y_{ik} - f_k(x_i))^2 $$

Onde $y_{ik}$ Ã© o valor real da k-Ã©sima saÃ­da para a i-Ã©sima observaÃ§Ã£o.

### 4. RetropropagaÃ§Ã£o (Backpropagation)

O objetivo do treinamento Ã© minimizar o erro total $R = \sum_{i=1}^N R_i$ ajustando os pesos da rede. Isso Ã© feito atravÃ©s do algoritmo de retropropagaÃ§Ã£o, que calcula os gradientes do erro em relaÃ§Ã£o aos pesos.

#### 4.1 Gradientes para a Camada de SaÃ­da

Para cada peso $\beta_{km}$ conectando a m-Ã©sima unidade oculta Ã  k-Ã©sima unidade de saÃ­da [12]:

$$ \frac{\partial R_i}{\partial \beta_{km}} = -2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i)z_{mi} $$

#### 4.2 Gradientes para a Camada Oculta

Para cada peso $\alpha_{m\ell}$ conectando a $\ell$-Ã©sima entrada Ã  m-Ã©sima unidade oculta [12]:

$$ \frac{\partial R_i}{\partial \alpha_{m\ell}} = -\sum_{k=1}^K 2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i)\beta_{km}\sigma'(\alpha_m^T x_i)x_{i\ell} $$

### 5. AtualizaÃ§Ã£o dos Pesos

Os pesos sÃ£o atualizados iterativamente usando o gradiente descendente:

$$ \beta_{km}^{(new)} = \beta_{km}^{(old)} - \eta \sum_{i=1}^N \frac{\partial R_i}{\partial \beta_{km}} $$

$$ \alpha_{m\ell}^{(new)} = \alpha_{m\ell}^{(old)} - \eta \sum_{i=1}^N \frac{\partial R_i}{\partial \alpha_{m\ell}} $$

Onde $\eta$ Ã© a taxa de aprendizagem.

> âš ï¸ **Nota Importante**: A escolha da taxa de aprendizagem Ã© crucial. Uma taxa muito alta pode levar Ã  divergÃªncia, enquanto uma taxa muito baixa pode resultar em convergÃªncia lenta.

### 6. EficiÃªncia Computacional

A eficiÃªncia do algoritmo de retropropagaÃ§Ã£o vem da sua capacidade de reutilizar cÃ¡lculos intermediÃ¡rios. Definimos:

$$ \delta_{ki} = -2(y_{ik} - f_k(x_i))g'_k(\beta_k^T z_i) $$
$$ s_{mi} = \sigma'(\alpha_m^T x_i)\sum_{k=1}^K \beta_{km}\delta_{ki} $$

Assim, podemos reescrever os gradientes como:

$$ \frac{\partial R_i}{\partial \beta_{km}} = \delta_{ki}z_{mi} $$
$$ \frac{\partial R_i}{\partial \alpha_{m\ell}} = s_{mi}x_{i\ell} $$

Isso permite que o algoritmo calcule os gradientes em duas passadas pela rede: uma forward para computar as ativaÃ§Ãµes e outra backward para computar os deltas e atualizar os pesos.

âœ”ï¸ **Ponto de Destaque**: A reutilizaÃ§Ã£o de cÃ¡lculos intermediÃ¡rios reduz a complexidade computacional de $O(W^2)$ para $O(W)$, onde $W$ Ã© o nÃºmero total de pesos na rede.

### QuestÃµes TÃ©cnicas

1. Como a escolha da funÃ§Ã£o de ativaÃ§Ã£o na camada oculta afeta a capacidade da rede neural de aprender relaÃ§Ãµes nÃ£o-lineares nos dados?

2. Explique por que o algoritmo de retropropagaÃ§Ã£o Ã© computacionalmente eficiente para treinar redes neurais. Como ele difere de um cÃ¡lculo direto dos gradientes?

3. Considerando uma rede neural com 100 entradas, 50 unidades ocultas e 10 saÃ­das, quantos parÃ¢metros (pesos e vieses) precisam ser aprendidos durante o treinamento?

### ImplementaÃ§Ã£o do Algoritmo

A implementaÃ§Ã£o do algoritmo de retropropagaÃ§Ã£o pode ser resumida nos seguintes passos [13]:

1. InicializaÃ§Ã£o dos pesos com valores aleatÃ³rios prÃ³ximos a zero.
2. Para cada Ã©poca de treinamento:
   a. PropagaÃ§Ã£o direta dos dados de entrada.
   b. CÃ¡lculo do erro na camada de saÃ­da.
   c. RetropropagaÃ§Ã£o do erro e cÃ¡lculo dos gradientes.
   d. AtualizaÃ§Ã£o dos pesos usando o gradiente descendente.

Exemplo simplificado em Python:

```python
import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

class NeuralNetwork:
    def __init__(self, x, y):
        self.input = x
        self.weights1 = np.random.rand(self.input.shape[1], 4) 
        self.weights2 = np.random.rand(4, 1)                 
        self.y = y
        self.output = np.zeros(y.shape)
        
    def feedforward(self):
        self.layer1 = sigmoid(np.dot(self.input, self.weights1))
        self.output = sigmoid(np.dot(self.layer1, self.weights2))
        
    def backprop(self):
        d_weights2 = np.dot(self.layer1.T, 2*(self.y - self.output) * sigmoid_derivative(self.output))
        d_weights1 = np.dot(self.input.T,  np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1))
    
        self.weights1 += d_weights1
        self.weights2 += d_weights2
```

Este exemplo demonstra uma implementaÃ§Ã£o bÃ¡sica do algoritmo de retropropagaÃ§Ã£o para uma rede neural com uma camada oculta.

#### QuestÃµes TÃ©cnicas/TeÃ³ricas

1. Como o algoritmo de retropropagaÃ§Ã£o lida com o problema do desvanecimento do gradiente em redes neurais profundas?
2. Explique como a escolha da funÃ§Ã£o de ativaÃ§Ã£o pode impactar a eficÃ¡cia do algoritmo de retropropagaÃ§Ã£o.

### Variantes e OtimizaÃ§Ãµes

O algoritmo de retropropagaÃ§Ã£o bÃ¡sico pode ser estendido e otimizado de vÃ¡rias formas [13]:

1. **Momentum**: Adiciona um termo de momento para acelerar a convergÃªncia e evitar mÃ­nimos locais.
2. **Aprendizado em Lote vs. Online**: O aprendizado em lote atualiza os pesos apÃ³s processar todo o conjunto de treinamento, enquanto o online atualiza apÃ³s cada amostra.
3. **Taxa de Aprendizado Adaptativa**: Ajusta a taxa de aprendizado durante o treinamento para melhorar a convergÃªncia.

> â— **Ponto de AtenÃ§Ã£o**: A escolha entre aprendizado em lote e online pode afetar significativamente a velocidade de convergÃªncia e a qualidade da soluÃ§Ã£o final.

### AplicaÃ§Ãµes e LimitaÃ§Ãµes

O algoritmo de retropropagaÃ§Ã£o Ã© amplamente utilizado em diversos domÃ­nios, incluindo:

- Reconhecimento de padrÃµes
- Processamento de linguagem natural
- VisÃ£o computacional

No entanto, tambÃ©m apresenta limitaÃ§Ãµes:

ğŸ‘ **Vantagens**:
- EficiÃªncia computacional para redes feed-forward
- Capacidade de aprender representaÃ§Ãµes complexas

ğŸ‘ **Desvantagens**:
- Suscetibilidade a mÃ­nimos locais
- Dificuldade em treinar redes muito profundas (problema do desvanecimento/explosÃ£o do gradiente)

### ConclusÃ£o

O algoritmo de retropropagaÃ§Ã£o revolucionou o treinamento de redes neurais artificiais, proporcionando um mÃ©todo eficiente para ajustar os pesos da rede e minimizar o erro de previsÃ£o [9]. Sua capacidade de lidar com funÃ§Ãµes nÃ£o-lineares complexas e sua eficiÃªncia computacional o tornaram a base para muitos avanÃ§os em aprendizado profundo. No entanto, desafios como o desvanecimento do gradiente em redes profundas levaram ao desenvolvimento de tÃ©cnicas mais avanÃ§adas, como redes residuais e normalizaÃ§Ã£o em lote, que complementam e estendem as capacidades do algoritmo de retropropagaÃ§Ã£o bÃ¡sico [13].

### QuestÃµes AvanÃ§adas

1. Compare o desempenho e a eficÃ¡cia do algoritmo de retropropagaÃ§Ã£o com mÃ©todos de otimizaÃ§Ã£o de segunda ordem, como o algoritmo de Levenberg-Marquardt, para o treinamento de redes neurais profundas.

2. Discuta como as tÃ©cnicas de regularizaÃ§Ã£o, como dropout e normalizaÃ§Ã£o em lote, interagem com o processo de retropropagaÃ§Ã£o e afetam a convergÃªncia do treinamento.

3. Explique como o algoritmo de retropropagaÃ§Ã£o poderia ser modificado para treinar redes neurais recorrentes, considerando a natureza temporal das dependÃªncias em sequÃªncias de dados.

### ReferÃªncias

[9] "Typically we don't want the global minimizer of R(Î¸), as this is likely to be an overfit solution. Instead some regularization is needed: this is achieved directly through a penalty term, or indirectly by early stopping." (Trecho de ESL II)

[12] "Here is back-propagation in detail for squared error loss. Let z_mi = Ïƒ(Î±_0m + Î±_m^T x_i), from (11.5) and let z_i = (z_1i, z_2i, ..., z_Mi). Then we have R(Î¸) â‰¡ Î£Ri = Î£(y_ik - f_k(x_i))^2, with derivatives âˆ‚R_i/âˆ‚Î²_km = -2(y_ik - f_k(x_i))g'_k(Î²_k^T z_i)z_mi, âˆ‚R_i/âˆ‚Î±_mâ„“ = -Î£2(y_ik - f_k(x_i))g'_k(Î²_k^T z_i)Î²_km Ïƒ'(Î±_m^T x_i)x_iâ„“." (Trecho de ESL II)

[13] "Given these derivatives, a gradient descent update at the (r + 1)st iteration has the form Î²_km^(r+1) = Î²_km^(r) - Î³_r Î£ âˆ‚R_i/âˆ‚Î²_km^(r), Î±_mâ„“^(r+1) = Î±_mâ„“^(r) - Î³_r Î£ âˆ‚R_i/âˆ‚Î±_mâ„“^(r), where Î³_r is the learning rate, discussed below." (Trecho de ESL II)