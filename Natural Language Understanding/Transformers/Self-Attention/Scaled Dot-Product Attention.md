## Scaled Dot-Product Attention: Fundamentos, Formula√ß√£o Matem√°tica e Impacto na Estabilidade de Modelos

<img src="C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240829113857364.png" alt="image-20240829113857364" style="zoom:67%;" />

<img src="C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240829113918302.png" alt="image-20240829113918302" style="zoom:67%;" />

### Introdu√ß√£o

A **Scaled Dot-Product Attention** √© um componente fundamental dos modelos Transformer, revolucionando o processamento de sequ√™ncias em tarefas de aprendizado profundo, especialmente em processamento de linguagem natural (NLP) [1]. Este mecanismo permite que os modelos foquem seletivamente em diferentes partes da entrada, melhorando significativamente a capacidade de capturar depend√™ncias de longo alcance e rela√ß√µes complexas entre os elementos de uma sequ√™ncia.

Este resumo explora em profundidade a formula√ß√£o matem√°tica da ==aten√ß√£o por produto escalar escalado==, sua motiva√ß√£o, implementa√ß√£o e ==impacto na estabilidade e desempenho dos modelos==. Analisaremos tamb√©m como ==diferentes fatores de escala podem influenciar o comportamento e a efic√°cia dos modelos Transformer.==

### Conceitos Fundamentais

| Conceito                  | Explica√ß√£o                                                   |
| ------------------------- | ------------------------------------------------------------ |
| **Dot-Product Attention** | Mecanismo de aten√ß√£o baseado no ==produto escalar entre queries e keys== para computar scores de aten√ß√£o. [2] |
| **Scaling Factor**        | ==Fator introduzido para mitigar instabilidades num√©ricas em dimens√µes elevadas, tipicamente ‚àödk. [2]== |
| **Softmax**               | Fun√ß√£o aplicada aos scores de aten√ß√£o para obter pesos normalizados. [2] |

> ‚ö†Ô∏è **Nota Importante**: A escala no dot-product attention √© crucial para ==manter gradientes est√°veis durante o treinamento==, especialmente em modelos com alta dimensionalidade.

### Formula√ß√£o Matem√°tica do Scaled Dot-Product Attention

A aten√ß√£o por produto escalar escalado √© definida matematicamente como [2]:
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

Onde:
- $Q \in \mathbb{R}^{n \times d_k}$: matriz de queries
- $K \in \mathbb{R}^{m \times d_k}$: matriz de keys
- $V \in \mathbb{R}^{m \times d_v}$: matriz de values
- $d_k$: ==dimens√£o das queries e keys==
- $d_v$: dimens√£o dos values
- $n$: n√∫mero de queries
- $m$: n√∫mero de key-value pairs

Vamos analisar cada componente desta f√≥rmula:

1. **Produto Matricial $QK^T$**: 
   - ==Computa os scores de aten√ß√£o brutos entre cada query e key.==
   - Resultado: matriz $n \times m$ de scores de aten√ß√£o.

2. **Fator de Escala $\frac{1}{\sqrt{d_k}}$**:
   - ==Mitiga o problema de gradientes pequenos em dimens√µes elevadas.==
   - ==Mant√©m a vari√¢ncia dos scores de aten√ß√£o aproximadamente constante==, independentemente de $d_k$.

3. **Softmax**:
   - Normaliza os scores de aten√ß√£o escalados.
   - Transforma scores em pesos de aten√ß√£o entre 0 e 1, somando 1 para cada query.

4. **Multiplica√ß√£o por $V$**:
   - Pondera os values pelos pesos de aten√ß√£o normalizados.
   - Produz a sa√≠da final da camada de aten√ß√£o.

> ‚úîÔ∏è **Ponto de Destaque**: ==A escala $\frac{1}{\sqrt{d_k}}$ √© crucial para evitar que o argumento do softmax cres√ßa descontroladamente com $d_k$==, o que levaria a gradientes extremamente pequenos.

#### Demonstra√ß√£o da Necessidade de Escala

![image-20240829113115775](C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240829113115775.png)

Para entender por que a escala √© necess√°ria, consideremos o comportamento do produto escalar em alta dimens√£o:

1. Assuma que elementos de $Q$ e $K$ s√£o vari√°veis aleat√≥rias independentes com m√©dia 0 e vari√¢ncia 1.
2. O produto escalar $q \cdot k$ para uma query $q$ e uma key $k$ tem:
   - $\mathbb{E}[q \cdot k] = 0$
   - $\text{Var}(q \cdot k) = d_k$

3. Sem escala, ==√† medida que $d_k$ aumenta, a vari√¢ncia do produto escalar cresce linearmente==, levando a valores extremos no softmax.

4. Aplicando a escala $\frac{1}{\sqrt{d_k}}$:
   - $\mathbb{E}[\frac{q \cdot k}{\sqrt{d_k}}] = 0$
   - $\text{Var}(\frac{q \cdot k}{\sqrt{d_k}}) = 1$

Isso mant√©m a vari√¢ncia constante, independentemente de $d_k$, estabilizando o treinamento.

#### Quest√µes T√©cnicas/Te√≥ricas

1. Como a vari√¢ncia dos scores de aten√ß√£o muda se usarmos um fator de escala $\frac{1}{d_k}$ em vez de $\frac{1}{\sqrt{d_k}}$? Explique o impacto potencial no treinamento do modelo.

2. Se aumentarmos $d_k$ em um modelo Transformer, mantendo outras dimens√µes constantes, como isso afetar√° o n√∫mero de par√¢metros e o custo computacional da camada de aten√ß√£o? Justifique matematicamente.

### Implementa√ß√£o em PyTorch

Vamos implementar a fun√ß√£o de Scaled Dot-Product Attention em PyTorch:

```python
import torch
import torch.nn.functional as F

def scaled_dot_product_attention(query, key, value, mask=None):
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k).float())
    
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    
    attention_weights = F.softmax(scores, dim=-1)
    return torch.matmul(attention_weights, value), attention_weights
```

Esta implementa√ß√£o:
1. Calcula os scores de aten√ß√£o com o produto escalar escalado.
2. Aplica uma m√°scara opcional (√∫til para aten√ß√£o causal em decodificadores).
3. Normaliza os scores com softmax.
4. Computa a sa√≠da ponderada e retorna tamb√©m os pesos de aten√ß√£o.

> ‚ùó **Ponto de Aten√ß√£o**: A aplica√ß√£o da m√°scara com `-1e9` antes do softmax efetivamente zera a aten√ß√£o para posi√ß√µes mascaradas.

### Impacto de Diferentes Fatores de Escala

O fator de escala $\frac{1}{\sqrt{d_k}}$ foi escolhido empiricamente por Vaswani et al. (2017) [2], mas √© interessante considerar o impacto de diferentes fatores:

1. **Sem Escala ($\frac{1}{1}$)**:
   - üëé Gradientes extremamente pequenos para $d_k$ grande.
   - üëé Treinamento inst√°vel e converg√™ncia lenta.

2. **Escala Padr√£o ($\frac{1}{\sqrt{d_k}}$)**:
   - üëç Balanceia bem a magnitude dos gradientes.
   - üëç Funciona bem para uma ampla gama de arquiteturas.

3. **Escala Quadr√°tica ($\frac{1}{d_k}$)**:
   - üëç Pode ser ben√©fica para dimens√µes muito altas.
   - üëé Risco de subamortecer o sinal para dimens√µes menores.

4. **Escala Adaptativa**:
   - Ideia: Ajustar o fator de escala durante o treinamento.
   - üëç ==Potencial para melhor adapta√ß√£o a diferentes regimes.==
   - üëé ==Aumenta a complexidade do modelo e pode ser inst√°vel.==

> üí° **Insight**: A escolha do fator de escala ideal pode depender da arquitetura espec√≠fica e da tarefa. Experimentos emp√≠ricos s√£o cruciais para determinar o melhor fator para um dado modelo.

#### An√°lise Matem√°tica do Impacto da Escala

![image-20240829114439625](C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240829114439625.png)

Consideremos o gradiente da fun√ß√£o softmax em rela√ß√£o aos scores de aten√ß√£o:

$$
\frac{\partial \text{softmax}(x_i)}{\partial x_j} = \text{softmax}(x_i)(\delta_{ij} - \text{softmax}(x_j))
$$

Onde $\delta_{ij}$ √© o delta de Kronecker.

Para scores de aten√ß√£o $s = \frac{QK^T}{\alpha}$, onde $\alpha$ √© o fator de escala:

1. Se $\alpha$ for muito pequeno (ou ausente), $s$ ter√° valores grandes, levando a:
   - ==softmax(s) pr√≥ximo a one-hot vectors.==
   - Gradientes pr√≥ximos a zero, dificultando o aprendizado.

2. Se $\alpha$ for muito grande, $s$ ter√° valores pequenos, resultando em:
   - ==softmax(s) pr√≥ximo a distribui√ß√£o uniforme.==
   - Gradientes pequenos, mas n√£o t√£o pr√≥ximos de zero.

3. Com $\alpha = \sqrt{d_k}$:
   - ==Mant√©m $s$ em uma faixa que permite gradientes informativos.==
   - ==Facilita o fluxo de gradientes atrav√©s da rede.==

#### Quest√µes T√©cnicas/Te√≥ricas

1. Como o fator de escala afeta a satura√ß√£o da fun√ß√£o softmax? Descreva matematicamente como isso impacta os gradientes durante o backpropagation.

2. Se quis√©ssemos implementar um fator de escala adaptativo, que depende da distribui√ß√£o dos valores em Q e K, como poder√≠amos formular isso? Considere usar estat√≠sticas como a vari√¢ncia dos elementos de QK^T.

### Conclus√£o

A Scaled Dot-Product Attention √© um componente crucial dos modelos Transformer, permitindo uma aten√ß√£o eficiente e est√°vel sobre sequ√™ncias de entrada. O fator de escala $\frac{1}{\sqrt{d_k}}$ desempenha um papel fundamental na estabiliza√ß√£o do treinamento, especialmente para modelos de alta dimensionalidade [2].

Embora $\frac{1}{\sqrt{d_k}}$ seja o padr√£o, a escolha do fator de escala pode impactar significativamente o desempenho e a estabilidade do modelo. Pesquisas futuras podem explorar fatores de escala adaptativos ou espec√≠ficos para determinadas arquiteturas ou tarefas.

A compreens√£o profunda da matem√°tica por tr√°s da aten√ß√£o escalada √© essencial para o desenvolvimento e otimiza√ß√£o de modelos Transformer avan√ßados, abrindo caminho para inova√ß√µes em arquiteturas de aten√ß√£o e suas aplica√ß√µes em diversos dom√≠nios do aprendizado profundo.

### Quest√µes Avan√ßadas

1. Considere um modelo Transformer com m√∫ltiplas cabe√ßas de aten√ß√£o. Como a escolha de diferentes fatores de escala para cada cabe√ßa poderia afetar a capacidade do modelo de capturar diferentes tipos de rela√ß√µes? Proponha um m√©todo para determinar fatores de escala √≥timos para cada cabe√ßa.

2. Na pr√°tica, observa-se que alguns modelos Transformer muito grandes (como GPT-3) usam fatores de escala ligeiramente diferentes de $\sqrt{d_k}$. Desenvolva uma an√°lise te√≥rica que possa explicar por que desvios do fator padr√£o podem ser ben√©ficos em certos regimes de escala.

3. O mecanismo de aten√ß√£o pode ser visto como uma forma de recupera√ß√£o de informa√ß√£o soft. Como a escolha do fator de escala afeta esta interpreta√ß√£o? Relacione sua resposta com conceitos de teoria da informa√ß√£o, como entropia e informa√ß√£o m√∫tua entre queries e keys.

### Refer√™ncias

[1] "Transformers s√£o uma arquitetura de rede neural que revolucionou o processamento de sequ√™ncias em tarefas de aprendizado profundo, especialmente em processamento de linguagem natural (NLP)." (Trecho de Transformers and Large Language Models - Chapter 10)

[2] "The core intuition of attention is the idea of comparing an item of interest to a collection of other items in a way that reveals their relevance in the current context. In the case of self-attention for language, the set of comparisons are to other words (or tokens) within a given sequence. The result of these comparisons is then used to compute an output sequence for the current input sequence." (Trecho de Transformers and Large Language Models - Chapter 10)

[3] "To capture these three different roles, transformers introduce weight matrices WQ, WK, and WV. These weights will be used to project each input vector xi into a representation of its role as a key, query, or value." (Trecho de Transformers and Large Language Models - Chapter 10)

[4] "Given these projections, the score between a current focus of attention, x, and an element in the preceding context, x, consists of a dot product between its query vector qi and the preceding element's key vectors k. This dot product has the right shape since both the query and the key are of dimensionality 1 √ó d." (Trecho de Transformers and Large Language Models - Chapter 10)

[5] "There is one final part of the self-attention model. The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating large values can lead to numerical issues and to an effective loss of gradients during training. To avoid this, we scale down the result of the dot product, by dividing it by a factor related to the size of the embeddings. A typical approach is to divide by the square root of the dimensionality of the query and key vectors (dk)" (Trecho de Transformers and Large Language Models - Chapter 10)

[6] "score(x, x ) = qi ¬∑ k ji j ‚àödk" (Trecho de Transformers and Large Language Models - Chapter 10)

[7] "A = SelfAttention(Q, K, V) = softmax(QK·µÄ)V‚àödk" (Trecho de Transformers and Large Language Models - Chapter 10)

[8] "The values of Nc, Dc, Cc, Œ±N, Œ±D, and Œ±C depend on the exact transformer architecture, tokenization, and vocabulary size, so rather than all the precise values, scaling laws focus on the relationship with loss." (Trecho de Transformers and Large Language Models - Chapter 10)