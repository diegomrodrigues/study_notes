# Probabilistic vs. Discriminative Approaches: Distinguishing between probabilistic classifiers and discriminative classifiers

<imagem: Um diagrama comparativo mostrando Na√Øve Bayes (representado por uma rede bayesiana) de um lado e SVM/Perceptron (representado por um hiperplano separador) do outro, com setas apontando para suas caracter√≠sticas distintas>

## Introdu√ß√£o

Na classifica√ß√£o de texto e aprendizado de m√°quina em geral, duas abordagens fundamentais se destacam: os classificadores probabil√≠sticos e os discriminativos. Essa distin√ß√£o √© crucial para entender as diferentes metodologias de aprendizado e suas implica√ß√µes te√≥ricas e pr√°ticas [1]. Este resumo se concentra em distinguir essas duas abordagens, focando especificamente no Na√Øve Bayes como exemplo de classificador probabil√≠stico, e no perceptron e SVM (Support Vector Machine) como exemplos de classificadores discriminativos.

Os classificadores probabil√≠sticos, como o Na√Øve Bayes, baseiam-se na modelagem da distribui√ß√£o de probabilidade conjunta dos dados e r√≥tulos. Por outro lado, os classificadores discriminativos, como o perceptron e o SVM, focam diretamente na tarefa de discrimina√ß√£o entre classes, sem modelar explicitamente a distribui√ß√£o dos dados [2]. Essa diferen√ßa fundamental leva a distintas abordagens de aprendizado, representa√ß√£o de conhecimento e desempenho em v√°rias tarefas de classifica√ß√£o.

## Conceitos Fundamentais

| Conceito                         | Explica√ß√£o                                                   |
| -------------------------------- | ------------------------------------------------------------ |
| **Classificador Probabil√≠stico** | Modela a distribui√ß√£o de probabilidade conjunta p(X,Y) dos dados X e r√≥tulos Y. No caso do Na√Øve Bayes, isso √© feito atrav√©s da decomposi√ß√£o p(X,Y) = p(Y)p(X |
| **Classificador Discriminativo** | Foca diretamente na modelagem da probabilidade condicional p(Y |
| **Na√Øve Bayes**                  | Um classificador probabil√≠stico que faz a suposi√ß√£o "ing√™nua" de independ√™ncia condicional entre as caracter√≠sticas dado a classe. Isso simplifica significativamente o c√°lculo da verossimilhan√ßa [5]. |
| **Perceptron**                   | Um classificador linear discriminativo que aprende atualizando pesos iterativamente com base nos erros de classifica√ß√£o. √â um dos algoritmos mais simples de aprendizado de m√°quina [6]. |
| **SVM (Support Vector Machine)** | Um classificador discriminativo que busca encontrar o hiperplano de margem m√°xima que separa as classes. √â conhecido por sua capacidade de generaliza√ß√£o e robustez [7]. |

> ‚ö†Ô∏è **Nota Importante**: A escolha entre abordagens probabil√≠sticas e discriminativas pode ter um impacto significativo no desempenho do modelo, dependendo da natureza dos dados e da tarefa em quest√£o [8].

### Modelagem Probabil√≠stica vs. Discriminativa

<imagem: Gr√°fico comparativo mostrando a fun√ß√£o de decis√£o de um classificador Na√Øve Bayes (curvas de probabilidade) e um SVM (hiperplano) em um espa√ßo bidimensional>

A distin√ß√£o fundamental entre as abordagens probabil√≠stica e discriminativa reside na forma como elas modelam o problema de classifica√ß√£o [9].

#### Modelagem Probabil√≠stica (Na√Øve Bayes)

O Na√Øve Bayes, como classificador probabil√≠stico, modela a distribui√ß√£o conjunta p(X,Y) [10]. Para um problema de classifica√ß√£o bin√°ria, temos:

$$
p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}
$$

Onde:
- p(Y|X) √© a probabilidade posterior
- p(X|Y) √© a verossimilhan√ßa
- p(Y) √© a probabilidade a priori
- p(X) √© a evid√™ncia (normalizador)

A suposi√ß√£o "ing√™nua" de independ√™ncia condicional do Na√Øve Bayes permite decompor a verossimilhan√ßa [11]:

$$
p(X|Y) = \prod_{j=1}^V p(X_j|Y)
$$

Onde V √© o n√∫mero de caracter√≠sticas.

#### Modelagem Discriminativa (Perceptron e SVM)

Os classificadores discriminativos, como o perceptron e o SVM, modelam diretamente a fronteira de decis√£o entre as classes [12]. Para um classificador linear, a fun√ß√£o de decis√£o tem a forma:

$$
f(X) = \text{sign}(\theta \cdot X + b)
$$

Onde:
- Œ∏ √© o vetor de pesos
- b √© o vi√©s
- X √© o vetor de caracter√≠sticas

No caso do SVM, busca-se maximizar a margem entre as classes [13]:

$$
\text{max}_{\theta, b} \frac{2}{||\theta||} \text{ sujeito a } y_i(\theta \cdot x_i + b) \geq 1, \forall i
$$

#### Perguntas Te√≥ricas

1. Derive a express√£o para a atualiza√ß√£o de pesos do perceptron e explique como ela difere conceitualmente da estimativa de m√°xima verossimilhan√ßa no Na√Øve Bayes.
2. Considerando um conjunto de dados linearmente separ√°vel, prove que o SVM de margem r√≠gida sempre encontrar√° uma solu√ß√£o, enquanto o perceptron pode n√£o convergir em um n√∫mero finito de itera√ß√µes.
3. Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas, em compara√ß√£o com abordagens discriminativas.

### Estima√ß√£o de Par√¢metros

A estima√ß√£o de par√¢metros √© um aspecto crucial que diferencia as abordagens probabil√≠sticas e discriminativas [14].

#### Na√Øve Bayes

No Na√Øve Bayes, os par√¢metros s√£o estimados usando o princ√≠pio da m√°xima verossimilhan√ßa [15]. Para um vocabul√°rio de V palavras e K classes, temos:

$$
\phi_{y,j} = \frac{\text{count}(y,j)}{\sum_{j'=1}^V \text{count}(y,j')} = \frac{\sum_{i:y^{(i)}=y} x_j^{(i)}}{\sum_{j'=1}^V \sum_{i:y^{(i)}=y} x_{j'}^{(i)}}
$$

Onde count(y,j) √© a contagem da palavra j em documentos com r√≥tulo y.

Para evitar problemas com palavras n√£o vistas no treinamento, √© comum usar suaviza√ß√£o de Laplace [16]:

$$
\phi_{y,j} = \frac{\alpha + \text{count}(y,j)}{V\alpha + \sum_{j'=1}^V \text{count}(y,j')}
$$

Onde Œ± √© o hiperpar√¢metro de suaviza√ß√£o.

#### Perceptron

O perceptron atualiza seus pesos de forma online, baseando-se nos erros de classifica√ß√£o [17]:

$$
\theta^{(t)} = \theta^{(t-1)} + f(x^{(i)}, y^{(i)}) - f(x^{(i)}, \hat{y})
$$

Onde $\hat{y}$ √© a previs√£o do modelo e y^(i) √© o r√≥tulo verdadeiro.

#### SVM

O SVM resolve um problema de otimiza√ß√£o quadr√°tica para encontrar o hiperplano de margem m√°xima [18]:

$$
\min_{\theta, b} \frac{1}{2} ||\theta||^2 + C \sum_{i=1}^N \xi_i
$$

Sujeito a:
$$
y_i(\theta \cdot x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad \forall i
$$

Onde $\xi_i$ s√£o vari√°veis de folga e C √© um hiperpar√¢metro de regulariza√ß√£o.

> ‚ùó **Ponto de Aten√ß√£o**: A estima√ß√£o de par√¢metros em modelos discriminativos geralmente envolve otimiza√ß√£o num√©rica, enquanto em modelos probabil√≠sticos como Na√Øve Bayes, muitas vezes √© poss√≠vel obter estimativas de forma fechada [19].

### Fun√ß√µes de Perda e Otimiza√ß√£o

As fun√ß√µes de perda e os m√©todos de otimiza√ß√£o utilizados s√£o fundamentalmente diferentes entre as abordagens probabil√≠sticas e discriminativas [20].

#### Na√Øve Bayes

A fun√ß√£o objetivo do Na√Øve Bayes √© a log-verossimilhan√ßa [21]:

$$
\mathcal{L}(\phi, \mu) = \sum_{i=1}^N \log p_\text{mult}(x^{(i)}; \phi_{y(i)}) + \log p_\text{cat}(y^{(i)}; \mu)
$$

A otimiza√ß√£o desta fun√ß√£o leva √†s estimativas de m√°xima verossimilhan√ßa mencionadas anteriormente.

#### Perceptron

O perceptron minimiza uma aproxima√ß√£o da perda de dobradi√ßa (hinge loss) [22]:

$$
\ell_\text{PERCEPTRON}(\theta; x^{(i)}, y^{(i)}) = \max_{\hat{y} \in Y} \theta \cdot f(x^{(i)}, \hat{y}) - \theta \cdot f(x^{(i)}, y^{(i)})
$$

#### SVM

O SVM minimiza uma combina√ß√£o de perda de dobradi√ßa e regulariza√ß√£o L2 [23]:

$$
L_\text{SVM} = \frac{\lambda}{2} ||\theta||^2_2 + \sum_{i=1}^N (\max_{y \in Y} [\theta \cdot f(x^{(i)}, y) + c(y^{(i)}, y)] - \theta \cdot f(x^{(i)}, y^{(i)}))_+
$$

> ‚úîÔ∏è **Destaque**: A escolha da fun√ß√£o de perda e do m√©todo de otimiza√ß√£o tem implica√ß√µes significativas na interpretabilidade do modelo, na velocidade de converg√™ncia e na capacidade de generaliza√ß√£o [24].

### Vantagens e Desvantagens

| üëç Vantagens                                                  | üëé Desvantagens                                               |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Na√Øve Bayes**: Simples, r√°pido de treinar, bom com dados esparsos [25] | **Na√Øve Bayes**: Suposi√ß√£o de independ√™ncia pode ser irrealista, pode sofrer com o problema de probabilidade zero [26] |
| **Perceptron**: Simples de implementar, online e eficiente [27] | **Perceptron**: Pode n√£o convergir para dados n√£o linearmente separ√°veis, sens√≠vel √† ordem dos dados [28] |
| **SVM**: Boa generaliza√ß√£o, eficaz em espa√ßos de alta dimens√£o [29] | **SVM**: Treinamento pode ser computacionalmente intensivo, escolha de kernel pode ser desafiadora [30] |

#### Perguntas Te√≥ricas

1. Derive a express√£o para o gradiente da fun√ß√£o de perda do SVM e compare-a com o gradiente da log-verossimilhan√ßa do Na√Øve Bayes. Discuta as implica√ß√µes dessas diferen√ßas na otimiza√ß√£o.
2. Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas, em compara√ß√£o com SVM e perceptron.
3. Considerando um conjunto de dados n√£o linearmente separ√°vel, prove que o SVM com kernel pode encontrar uma solu√ß√£o, enquanto o perceptron linear falhar√°. Discuta as implica√ß√µes te√≥ricas desta diferen√ßa.

### Implementa√ß√£o Avan√ßada

Aqui est√° um exemplo avan√ßado de implementa√ß√£o de um classificador SVM usando PyTorch, demonstrando como a abordagem discriminativa pode ser implementada de forma eficiente [31]:

```python
import torch
import torch.nn as nn
import torch.optim as optim

class SVM(nn.Module):
    def __init__(self, input_dim):
        super(SVM, self).__init__()
        self.linear = nn.Linear(input_dim, 1)
        
    def forward(self, x):
        return self.linear(x)

def hinge_loss(outputs, labels):
    return torch.mean(torch.clamp(1 - outputs.t() * labels, min=0))

def train_svm(model, X, y, learning_rate=0.01, num_epochs=1000):
    optimizer = optim.SGD(model.parameters(), lr=learning_rate)
    
    for epoch in range(num_epochs):
        optimizer.zero_grad()
        outputs = model(X)
        loss = hinge_loss(outputs, y)
        loss.backward()
        optimizer.step()
        
        if (epoch + 1) % 100 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Exemplo de uso
X = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 1.0], [4.0, 3.0]], dtype=torch.float32)
y = torch.tensor([1, 1, -1, -1], dtype=torch.float32)

model = SVM(input_dim=2)
train_svm(model, X, y)
```

Este c√≥digo implementa um SVM linear usando PyTorch, demonstrando como a otimiza√ß√£o baseada em gradiente pode ser aplicada a um classificador discriminativo [32].

## Conclus√£o

A distin√ß√£o entre classificadores probabil√≠sticos e discriminativos √© fundamental na teoria e pr√°tica do aprendizado de m√°quina. O Na√Øve Bayes, como representante da abordagem probabil√≠stica, oferece uma modelagem expl√≠cita da distribui√ß√£o dos dados, permitindo infer√™ncias probabil√≠sticas diretas. Por outro lado, classificadores discriminativos como o perceptron e o SVM focam na fronteira de decis√£o, muitas vezes alcan√ßando melhor desempenho em tarefas de classifica√ß√£o pura [33].

A escolha entre estas abordagens depende de v√°rios fatores, incluindo a natureza dos dados, o tamanho do conjunto de treinamento, a necessidade de interpretabilidade e os requisitos computacionais. Enquanto o Na√Øve Bayes pode ser mais adequado para conjuntos de dados pequenos ou quando estimativas de probabilidade s√£o necess√°rias, SVM e perceptron podem oferecer melhor desempenho em tarefas de classifica√ß√£o de alta dimensionalidade ou quando a suposi√ß√£o de independ√™ncia do Na√Øve Bayes √© violada [34].

Compreender as diferen√ßas te√≥ricas e pr√°ticas entre estas abordagens √© crucial para os cientistas de dados, permitindo a escolha informada de modelos e a interpreta√ß√£o adequada dos resultados em diversos cen√°rios de aprendizado de m√°quina [35].

## Perguntas Te√≥ricas Avan√ßadas

1. Considere um problema de classifica√ß√£o bin√°ria com caracter√≠sticas X e r√≥tulos Y. Derive a express√£o para o erro de Bayes e compare-a com o limite inferior do erro de generaliza√ß√£o do SVM de margem r√≠gida. Discuta as implica√ß√µes te√≥ricas desta compara√ß√£o.

2. Prove que, para um conjunto de dados linearmente separ√°vel, o algoritmo do perceptron converge em um n√∫mero finito de itera√ß√µes. Compare essa garantia de converg√™ncia com a do SVM e discuta as implica√ß√µes pr√°ticas dessas diferen√ßas te√≥ricas.

3. Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas. Proponha e analise