# Abordagens Probabil√≠sticas vs. Discriminativas: Distinguindo entre Classificadores Probabil√≠sticos e Discriminativos

![Diagrama comparativo mostrando Na√Øve Bayes (representado por uma rede bayesiana) de um lado e SVM/Perceptron (representado por um hiperplano separador) do outro, com setas apontando para suas caracter√≠sticas distintas.]

## Introdu√ß√£o

Na classifica√ß√£o de texto e no aprendizado de m√°quina em geral, duas abordagens fundamentais se destacam: os classificadores **probabil√≠sticos** e os **discriminativos**. Compreender essa distin√ß√£o √© crucial para apreciar as diferentes metodologias de aprendizado e suas implica√ß√µes te√≥ricas e pr√°ticas [1]. ==Este resumo foca em distinguir essas duas abordagens, utilizando o **Na√Øve Bayes** como exemplo de classificador probabil√≠stico e o **Perceptron** e a **SVM** (Support Vector Machine) como exemplos de classificadores discriminativos.==

Os classificadores probabil√≠sticos, como o Na√Øve Bayes, ==baseiam-se na modelagem da distribui√ß√£o de probabilidade conjunta dos dados e r√≥tulos.== Por outro lado, os classificadores discriminativos, como o Perceptron e a SVM, ==focam diretamente na tarefa de discrimina√ß√£o entre classes, sem modelar explicitamente a distribui√ß√£o dos dados [2]==. Essa diferen√ßa fundamental leva a distintas abordagens de aprendizado, representa√ß√µes de conhecimento e desempenhos variados em diversas tarefas de classifica√ß√£o.

## Conceitos Fundamentais

| Conceito                         | Explica√ß√£o                                                   |
| -------------------------------- | ------------------------------------------------------------ |
| **Classificador Probabil√≠stico** | ==Modela a distribui√ß√£o de probabilidade conjunta $p(X, Y)$ dos dados $X$ e r√≥tulos $Y$.== No caso do Na√Øve Bayes, isso √© feito atrav√©s da decomposi√ß√£o $p(X, Y) = p(Y) p(X \mid Y)$. |
| **Classificador Discriminativo** | ==Foca diretamente na modelagem da probabilidade condicional $p(Y \mid X)$ ou na fronteira de decis√£o entre classes==, sem a necessidade de modelar a distribui√ß√£o dos dados [3]. |
| **Na√Øve Bayes**                  | Um classificador probabil√≠stico que faz a suposi√ß√£o "ing√™nua" de ==independ√™ncia condicional== entre as caracter√≠sticas dado a classe. Isso simplifica significativamente o c√°lculo da verossimilhan√ßa [4]. |
| **Perceptron**                   | Um classificador linear discriminativo que aprende atualizando pesos iterativamente com base nos erros de classifica√ß√£o. ==√â um dos algoritmos mais simples de aprendizado de m√°quina [5].== |
| **SVM (Support Vector Machine)** | Um classificador discriminativo que busca encontrar o hiperplano de margem m√°xima que separa as classes. ==√â conhecido por sua capacidade de generaliza√ß√£o e robustez [6].== |

> ‚ö†Ô∏è **Nota Importante**: A escolha entre abordagens probabil√≠sticas e discriminativas pode ter um impacto significativo no desempenho do modelo, dependendo da natureza dos dados e da tarefa em quest√£o [7].

### Modelagem Probabil√≠stica vs. Discriminativa

![Gr√°fico comparativo mostrando a fun√ß√£o de decis√£o de um classificador Na√Øve Bayes (curvas de probabilidade) e um SVM (hiperplano) em um espa√ßo bidimensional.]

A distin√ß√£o fundamental entre as abordagens probabil√≠stica e discriminativa reside na forma como elas modelam o problema de classifica√ß√£o [8].

#### Modelagem Probabil√≠stica (Na√Øve Bayes)

O Na√Øve Bayes, como classificador probabil√≠stico, modela a distribui√ß√£o conjunta $p(X, Y)$ [9]. Para um problema de classifica√ß√£o bin√°ria, temos:

$$
p(Y \mid X) = \frac{p(X \mid Y) p(Y)}{p(X)}
$$

Onde:

- $p(Y \mid X)$ √© a probabilidade posterior.
- $p(X \mid Y)$ √© a verossimilhan√ßa.
- $p(Y)$ √© a probabilidade a priori.
- $p(X)$ √© a evid√™ncia (constante de normaliza√ß√£o).

==A suposi√ß√£o "ing√™nua" de independ√™ncia condicional do Na√Øve Bayes permite decompor a verossimilhan√ßa [10]:==
$$
p(X \mid Y) = \prod_{j=1}^V p(X_j \mid Y)
$$

Onde $V$ √© o n√∫mero de caracter√≠sticas.

#### Modelagem Discriminativa (Perceptron e SVM)

==Os classificadores discriminativos, como o Perceptron e a SVM, modelam diretamente a fronteira de decis√£o entre as classes [11]==. Para um classificador linear, a fun√ß√£o de decis√£o tem a forma:
$$
f(X) = \text{sign}(\theta \cdot X + b)
$$

Onde:

- $\theta$ √© o vetor de pesos.
- $b$ √© o vi√©s.
- $X$ √© o vetor de caracter√≠sticas.

No caso da SVM, busca-se maximizar a margem entre as classes [12]:

$$
\max_{\theta, b} \quad \frac{2}{\lVert \theta \rVert} \quad \text{sujeito a} \quad y_i (\theta \cdot x_i + b) \geq 1, \quad \forall i
$$

#### Perguntas Te√≥ricas

1. **Derive a express√£o para a atualiza√ß√£o de pesos do Perceptron e explique como ela difere conceitualmente da estimativa de m√°xima verossimilhan√ßa no Na√Øve Bayes.**
2. **Considerando um conjunto de dados linearmente separ√°vel, prove que a SVM de margem r√≠gida sempre encontrar√° uma solu√ß√£o √≥tima, enquanto o Perceptron pode n√£o convergir em um n√∫mero finito de itera√ß√µes.**
3. **Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas, em compara√ß√£o com abordagens discriminativas.**

### Estima√ß√£o de Par√¢metros

A estima√ß√£o de par√¢metros √© um aspecto crucial que diferencia as abordagens probabil√≠sticas e discriminativas [13].

#### Na√Øve Bayes

No Na√Øve Bayes, os par√¢metros s√£o estimados usando o princ√≠pio da m√°xima verossimilhan√ßa [14]. Para um vocabul√°rio de $V$ palavras e $K$ classes, temos:

$$
\phi_{y,j} = \frac{\text{count}(y, j)}{\sum_{j'=1}^V \text{count}(y, j')} = \frac{\sum_{i: y^{(i)}=y} x_j^{(i)}}{\sum_{j'=1}^V \sum_{i: y^{(i)}=y} x_{j'}^{(i)}}
$$

Onde $\text{count}(y, j)$ √© a contagem da palavra $j$ em documentos com r√≥tulo $y$.

==Para evitar problemas com palavras n√£o vistas no treinamento, √© comum usar **suaviza√ß√£o de Laplace** [15]:==
$$
\phi_{y,j} = \frac{\alpha + \text{count}(y, j)}{V\alpha + \sum_{j'=1}^V \text{count}(y, j')}
$$

Onde $\alpha$ √© o hiperpar√¢metro de suaviza√ß√£o.

#### Perceptron

O Perceptron atualiza seus pesos de forma online, baseando-se nos erros de classifica√ß√£o [16]:

$$
\theta^{(t)} = \theta^{(t-1)} + y^{(i)} x^{(i)}
$$

Se a previs√£o est√° incorreta, ou seja, se $y^{(i)} (\theta^{(t-1)} \cdot x^{(i)}) \leq 0$.

#### SVM

A SVM resolve um problema de otimiza√ß√£o quadr√°tica para encontrar o hiperplano de margem m√°xima [17]:

$$
\min_{\theta, b} \quad \frac{1}{2} \lVert \theta \rVert^2 + C \sum_{i=1}^N \xi_i
$$

Sujeito a:

$$
y_i (\theta \cdot x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad \forall i
$$

Onde $\xi_i$ s√£o vari√°veis de folga e $C$ √© um hiperpar√¢metro de regulariza√ß√£o.

> ‚ùó **Ponto de Aten√ß√£o**: A estima√ß√£o de par√¢metros em modelos discriminativos geralmente envolve otimiza√ß√£o num√©rica complexa, enquanto em modelos probabil√≠sticos como o Na√Øve Bayes, muitas vezes √© poss√≠vel obter estimativas de forma fechada [18].

### Fun√ß√µes de Perda e Otimiza√ß√£o

As fun√ß√µes de perda e os m√©todos de otimiza√ß√£o utilizados diferem fundamentalmente entre as abordagens probabil√≠sticas e discriminativas [19].

#### Na√Øve Bayes

==A fun√ß√£o objetivo do Na√Øve Bayes √© maximizar a **log-verossimilhan√ßa** [20]:==
$$
\mathcal{L}(\phi, \mu) = \sum_{i=1}^N \left[ \log p_{\text{mult}}(x^{(i)}; \phi_{y^{(i)}}) + \log p_{\text{cat}}(y^{(i)}; \mu) \right]
$$

A otimiza√ß√£o desta fun√ß√£o leva √†s estimativas de m√°xima verossimilhan√ßa mencionadas anteriormente.

#### Perceptron

O Perceptron minimiza uma ==fun√ß√£o de perda baseada nos erros de classifica√ß√£o [21]:==

$$
\ell_{\text{Perceptron}}(\theta; x^{(i)}, y^{(i)}) = - y^{(i)} (\theta \cdot x^{(i)})
$$

Atualizando os pesos apenas quando a classifica√ß√£o est√° incorreta.

#### SVM

A SVM minimiza uma ==combina√ß√£o de perda de **hinge** (dobradi√ßa) e regulariza√ß√£o $L2$ [22]:==

$$
L_{\text{SVM}} = \frac{1}{2} \lVert \theta \rVert^2 + C \sum_{i=1}^N \max \left( 0, 1 - y^{(i)} (\theta \cdot x^{(i)} + b) \right)
$$

> ‚úîÔ∏è **Destaque**: A escolha da fun√ß√£o de perda e do m√©todo de otimiza√ß√£o tem implica√ß√µes significativas na interpretabilidade do modelo, na velocidade de converg√™ncia e na capacidade de generaliza√ß√£o [23].

### Vantagens e Desvantagens

| üëç Vantagens                                                  | üëé Desvantagens                                               |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Na√Øve Bayes**: Simples, r√°pido de treinar, eficaz com dados esparsos [24]. | **Na√Øve Bayes**: A suposi√ß√£o de independ√™ncia pode ser irrealista, pode sofrer com o problema de probabilidade zero [25]. |
| **Perceptron**: Simples de implementar, online e eficiente [26]. | **Perceptron**: Pode n√£o convergir para dados n√£o linearmente separ√°veis, sens√≠vel √† ordem dos dados [27]. |
| **SVM**: Boa generaliza√ß√£o, eficaz em espa√ßos de alta dimens√£o [28]. | **SVM**: Treinamento pode ser computacionalmente intensivo, a escolha do kernel pode ser desafiadora [29]. |

#### Perguntas Te√≥ricas

1. **Derive a express√£o para o gradiente da fun√ß√£o de perda da SVM e compare-a com o gradiente da log-verossimilhan√ßa do Na√Øve Bayes. Discuta as implica√ß√µes dessas diferen√ßas na otimiza√ß√£o.**
2. **Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas, em compara√ß√£o com a SVM e o Perceptron.**
3. **Considerando um conjunto de dados n√£o linearmente separ√°vel, prove que a SVM com kernel pode encontrar uma solu√ß√£o, enquanto o Perceptron linear falhar√°. Discuta as implica√ß√µes te√≥ricas desta diferen√ßa.**

### Implementa√ß√£o Avan√ßada

Aqui est√° um exemplo avan√ßado de implementa√ß√£o de um classificador SVM usando **PyTorch**, demonstrando como a abordagem discriminativa pode ser implementada de forma eficiente [30]:

```python
import torch
import torch.nn as nn
import torch.optim as optim

class SVM(nn.Module):
    def __init__(self, input_dim):
        super(SVM, self).__init__()
        self.linear = nn.Linear(input_dim, 1)
        
    def forward(self, x):
        return self.linear(x)

def hinge_loss(outputs, labels):
    return torch.mean(torch.clamp(1 - outputs.view(-1) * labels, min=0))

def train_svm(model, X, y, learning_rate=0.01, num_epochs=1000):
    optimizer = optim.SGD(model.parameters(), lr=learning_rate)
    
    for epoch in range(num_epochs):
        optimizer.zero_grad()
        outputs = model(X)
        loss = hinge_loss(outputs, y)
        loss.backward()
        optimizer.step()
        
        if (epoch + 1) % 100 == 0:
            print(f'√âpoca [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Exemplo de uso
X = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 1.0], [4.0, 3.0]], dtype=torch.float32)
y = torch.tensor([1, 1, -1, -1], dtype=torch.float32)

model = SVM(input_dim=2)
train_svm(model, X, y)
```

Este c√≥digo implementa uma SVM linear usando PyTorch, demonstrando como a otimiza√ß√£o baseada em gradiente pode ser aplicada a um classificador discriminativo [31].

## Conclus√£o

A distin√ß√£o entre classificadores probabil√≠sticos e discriminativos √© fundamental na teoria e na pr√°tica do aprendizado de m√°quina. O Na√Øve Bayes, como representante da abordagem probabil√≠stica, oferece uma modelagem expl√≠cita da distribui√ß√£o dos dados, permitindo infer√™ncias probabil√≠sticas diretas. Por outro lado, classificadores discriminativos como o Perceptron e a SVM focam na fronteira de decis√£o, frequentemente alcan√ßando melhor desempenho em tarefas de classifica√ß√£o pura [32].

A escolha entre essas abordagens depende de v√°rios fatores, incluindo a natureza dos dados, o tamanho do conjunto de treinamento, a necessidade de interpretabilidade e os requisitos computacionais. Enquanto o Na√Øve Bayes pode ser mais adequado para conjuntos de dados pequenos ou quando estimativas de probabilidade s√£o necess√°rias, a SVM e o Perceptron podem oferecer melhor desempenho em tarefas de alta dimensionalidade ou quando a suposi√ß√£o de independ√™ncia do Na√Øve Bayes √© violada [33].

Compreender as diferen√ßas te√≥ricas e pr√°ticas entre essas abordagens √© crucial para os cientistas de dados, permitindo a escolha informada de modelos e a interpreta√ß√£o adequada dos resultados em diversos cen√°rios de aprendizado de m√°quina [34].

## Perguntas Te√≥ricas Avan√ßadas

1. **Considere um problema de classifica√ß√£o bin√°ria com caracter√≠sticas $X$ e r√≥tulos $Y$. Derive a express√£o para o erro de Bayes e compare-a com o limite inferior do erro de generaliza√ß√£o da SVM de margem r√≠gida. Discuta as implica√ß√µes te√≥ricas dessa compara√ß√£o.**

2. **Prove que, para um conjunto de dados linearmente separ√°vel, o algoritmo do Perceptron converge em um n√∫mero finito de itera√ß√µes. Compare essa garantia de converg√™ncia com a da SVM e discuta as implica√ß√µes pr√°ticas dessas diferen√ßas te√≥ricas.**

3. **Analise teoricamente como a suposi√ß√£o de independ√™ncia condicional do Na√Øve Bayes afeta sua capacidade de modelar intera√ß√µes complexas entre caracter√≠sticas. Proponha e analise alternativas que permitam ao Na√Øve Bayes capturar tais intera√ß√µes sem sacrificar demasiadamente a simplicidade computacional.**

---

**Refer√™ncias**

[1] Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.

[2] Ng, A. Y., & Jordan, M. I. (2002). On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes. *Advances in Neural Information Processing Systems*, 14.

[3] Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*. Springer.

[4] Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.

[5] Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. *Psychological Review*, 65(6), 386.

[6] Cortes, C., & Vapnik, V. (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297.

[7] Vapnik, V. N. (1998). *Statistical Learning Theory*. Wiley.

[8] Jordan, M. I. (2002). An introduction to probabilistic graphical models.

[9] Russell, S. J., & Norvig, P. (2016). *Artificial Intelligence: A Modern Approach*. Pearson.

[10] Mitchell, T. M. (1997). *Machine Learning*. McGraw-Hill.

[11] Cover, T., & Hart, P. (1967). Nearest neighbor pattern classification. *IEEE Transactions on Information Theory*, 13(1), 21-27.

[12] Sch√∂lkopf, B., & Smola, A. J. (2002). *Learning with Kernels*. MIT Press.

[13] Shawe-Taylor, J., & Cristianini, N. (2004). *Kernel Methods for Pattern Analysis*. Cambridge University Press.

[14] Duda, R. O., Hart, P. E., & Stork, D. G. (2001). *Pattern Classification*. Wiley.

[15] Lidstone, G. J. (1920). Note on the general case of the Bayes‚ÄìLaplace formula for inductive or a posteriori probabilities. *Transactions of the Faculty of Actuaries*, 8, 182-192.

[16] Freund, Y., & Schapire, R. E. (1999). Large margin classification using the perceptron algorithm. *Machine Learning*, 37(3), 277-296.

[17] Platt, J. (1999). *Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods*. MIT Press.

[18] Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.

[19] Rifkin, R., & Klautau, A. (2004). In defense of one-vs-all classification. *Journal of Machine Learning Research*, 5, 101-141.

[20] Bottou, L., & Bousquet, O. (2008). The tradeoffs of large scale learning. *Advances in Neural Information Processing Systems*, 20.

[21] Rosenblatt, F. (1957). The perceptron‚Äîa perceiving and recognizing automaton. *Report 85-460-1*, Cornell Aeronautical Laboratory.

[22] Collobert, R., & Bengio, S. (2004). Links between perceptrons, MLPs and SVMs. *Proceedings of the 21st International Conference on Machine Learning*.

[23] Joachims, T. (1998). Making large-scale SVM learning practical. *Advances in Kernel Methods*, 169-184.

[24] Zhang, H. (2004). The optimality of Naive Bayes. *AAAI*, 3(1), 562-567.

[25] Hand, D. J., & Yu, K. (2001). Idiot's Bayes‚Äînot so stupid after all? *International Statistical Review*, 69(3), 385-398.

[26] Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. *Journal of Computer and System Sciences*, 55(1), 119-139.

[27] Novikoff, A. B. J. (1962). On convergence proofs on perceptrons. *Proceedings of the Symposium on the Mathematical Theory of Automata*, 615-622.

[28] Burges, C. J. (1998). A tutorial on support vector machines for pattern recognition. *Data Mining and Knowledge Discovery*, 2(2), 121-167.

[29] Bennett, K. P., & Campbell, C. (2000). Support vector machines: Hype or hallelujah? *ACM SIGKDD Explorations Newsletter*, 2(2), 1-13.

[30] Paszke, A., et al. (2019). PyTorch: An imperative style, high-performance deep learning library. *Advances in Neural Information Processing Systems*, 32.

[31] Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*.

[32] Ng, A. Y. (2004). Feature selection, L1 vs. L2 regularization, and rotational invariance. *Proceedings of the Twenty-First International Conference on Machine Learning*.

[33] Domingos, P., & Pazzani, M. (1997). On the optimality of the simple Bayesian classifier under zero-one loss. *Machine Learning*, 29(2-3), 103-130.

[34] Koller, D., & Friedman, N. (2009). *Probabilistic Graphical Models: Principles and Techniques*. MIT Press.

[35] Vapnik, V. (2013). *The Nature of Statistical Learning Theory*. Springer Science & Business Media.