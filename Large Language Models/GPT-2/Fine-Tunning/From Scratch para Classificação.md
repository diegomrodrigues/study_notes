## Finetuning de Large Language Models para Classifica√ß√£o

![image-20240905182314233](C:\Users\diego.rodrigues\AppData\Roaming\Typora\typora-user-images\image-20240905182314233.png)

### Introdu√ß√£o

O finetuning de Large Language Models (LLMs) para tarefas espec√≠ficas tem se tornado uma pr√°tica essencial no campo do Processamento de Linguagem Natural (NLP). Este resumo aborda os aspectos t√©cnicos e matem√°ticos envolvidos no processo de adaptar um LLM pr√©-treinado, especificamente um modelo GPT, para uma tarefa de classifica√ß√£o de texto. Focamos em estrat√©gias de prepara√ß√£o de dados, modifica√ß√£o da arquitetura do modelo, t√©cnicas de treinamento e avalia√ß√£o de desempenho. [1]

### Conceitos Fundamentais

| Conceito                   | Explica√ß√£o                                                   |
| -------------------------- | ------------------------------------------------------------ |
| **Finetuning**             | Processo de ajuste fino de um modelo pr√©-treinado para uma tarefa espec√≠fica, mantendo a maior parte dos pesos originais. [2] |
| **Transfer Learning**      | T√©cnica que utiliza conhecimento adquirido em uma tarefa para melhorar o desempenho em outra tarefa relacionada. [3] |
| **Classifica√ß√£o de Texto** | Tarefa de atribuir uma ou mais categorias predefinidas a um texto de entrada, baseando-se em seu conte√∫do. [4] |

> ‚ö†Ô∏è **Nota Importante**: O finetuning de LLMs para classifica√ß√£o envolve um delicado equil√≠brio entre aproveitar o conhecimento pr√©-treinado e adaptar-se √† nova tarefa sem perder generaliza√ß√£o.

### 6.3 Criando Data Loaders

#### Lidando com Inputs de Comprimento Vari√°vel

Ao trabalhar com textos de comprimento vari√°vel em tarefas de classifica√ß√£o, dois principais desafios surgem: a necessidade de processar entradas em lotes (batches) e a limita√ß√£o do modelo em lidar com sequ√™ncias de comprimento fixo. Duas estrat√©gias principais s√£o empregadas para abordar esses desafios [5]:

1. **Truncamento**: Limita o comprimento das sequ√™ncias a um valor m√°ximo predefinido.
2. **Padding**: Adiciona tokens especiais para preencher sequ√™ncias mais curtas at√© um comprimento comum.

A escolha entre truncamento e padding depende da natureza dos dados e da tarefa espec√≠fica:

üëç **Vantagens do Truncamento**:
* Computacionalmente mais eficiente
* Evita o processamento de informa√ß√µes potencialmente irrelevantes

üëé **Desvantagens do Truncamento**:
* Pode resultar em perda de informa√ß√µes importantes em textos longos

üëç **Vantagens do Padding**:
* Preserva todas as informa√ß√µes originais
* Permite processamento de sequ√™ncias de qualquer comprimento

üëé **Desvantagens do Padding**:
* Aumenta o custo computacional
* Pode introduzir ru√≠do no processamento de tokens de padding

No contexto do finetuning de LLMs para classifica√ß√£o, a abordagem de padding √© frequentemente preferida, pois preserva informa√ß√µes potencialmente cruciais para a tarefa de classifica√ß√£o. [6]

#### Implementa√ß√£o de PyTorch Dataset e DataLoader

A implementa√ß√£o eficiente de um pipeline de dados para finetuning envolve o uso das classes `Dataset` e `DataLoader` do PyTorch. Vamos analisar uma implementa√ß√£o t√≠pica:

```python
class SpamDataset(Dataset):
    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):
        self.data = pd.read_csv(csv_file)
        self.encoded_texts = [tokenizer.encode(text) for text in self.data["Text"]]
        self.max_length = max_length or self._longest_encoded_length()
        self.encoded_texts = [
            encoded_text[:self.max_length] + 
            [pad_token_id] * (self.max_length - len(encoded_text))
            for encoded_text in self.encoded_texts
        ]

    def __getitem__(self, index):
        encoded = self.encoded_texts[index]
        label = self.data.iloc[index]["Label"]
        return (
            torch.tensor(encoded, dtype=torch.long),
            torch.tensor(label, dtype=torch.long)
        )

    def __len__(self):
        return len(self.data)

    def _longest_encoded_length(self):
        return max(len(encoded_text) for encoded_text in self.encoded_texts)
```

Esta implementa√ß√£o da classe `SpamDataset` realiza v√°rias opera√ß√µes cruciais [7]:

1. Carrega os dados de um arquivo CSV.
2. Tokeniza os textos usando um tokenizador espec√≠fico (geralmente o mesmo usado no pr√©-treinamento do LLM).
3. Determina o comprimento m√°ximo das sequ√™ncias.
4. Realiza padding ou truncamento das sequ√™ncias para um comprimento uniforme.
5. Converte os dados em tensores PyTorch.

> ‚úîÔ∏è **Destaque**: A determina√ß√£o din√¢mica do comprimento m√°ximo (`_longest_encoded_length`) permite adaptar o dataset a diferentes conjuntos de dados sem hardcoding.

Para criar um `DataLoader` eficiente, usa-se:

```python
train_loader = DataLoader(
    dataset=train_dataset,
    batch_size=8,
    shuffle=True,
    num_workers=0,
    drop_last=True
)
```

O `DataLoader` oferece v√°rias vantagens [8]:
- Carregamento em lotes (batching) autom√°tico
- Shuffling dos dados para melhor generaliza√ß√£o
- Paraleliza√ß√£o do carregamento de dados com `num_workers`
- Op√ß√£o de descartar o √∫ltimo lote incompleto com `drop_last`

#### T√©cnicas de Attention Masking para Sequ√™ncias com Padding

Ao trabalhar com sequ√™ncias padded, √© crucial implementar attention masking para evitar que o modelo atenda a tokens de padding. Isso √© tipicamente feito criando uma m√°scara de aten√ß√£o que atribui peso zero aos tokens de padding [9]:

```python
def create_attention_mask(input_ids, pad_token_id=50256):
    return (input_ids != pad_token_id).float()
```

Esta m√°scara √© ent√£o aplicada durante o c√°lculo da aten√ß√£o no modelo:

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V
$$

Onde $M$ √© a m√°scara de aten√ß√£o, tipicamente com valores muito negativos (e.g., -10000) nos locais correspondentes aos tokens de padding.

#### Perguntas T√©cnicas/Te√≥ricas

1. Como a escolha entre truncamento e padding pode afetar o desempenho de um modelo de classifica√ß√£o de texto? Considere cen√°rios com textos de comprimentos muito variados.

2. Explique como a implementa√ß√£o de attention masking ajuda a lidar com sequ√™ncias de comprimento vari√°vel em modelos baseados em aten√ß√£o. Quais seriam as consequ√™ncias de n√£o usar masking em sequ√™ncias com padding?

3. Discuta as implica√ß√µes de performance e mem√≥ria ao escolher diferentes valores para `batch_size` e `num_workers` no DataLoader do PyTorch. Como voc√™ otimizaria esses par√¢metros para um dataset muito grande?

Certamente. Vamos prosseguir com o pr√≥ximo t√≥pico do nosso resumo aprofundado.

### 6.4 Inicializando um modelo com pesos pr√©-treinados

<image: Um diagrama mostrando a transfer√™ncia de pesos de um modelo GPT pr√©-treinado para um novo modelo, com setas indicando quais camadas s√£o transferidas e quais s√£o inicializadas aleatoriamente>

#### Princ√≠pios de Transfer Learning em NLP

Transfer Learning √© uma t√©cnica fundamental no campo de NLP, especialmente quando se trabalha com Large Language Models. O princ√≠pio b√°sico envolve a utiliza√ß√£o de conhecimento adquirido em uma tarefa (geralmente mais geral e com grande volume de dados) para melhorar o desempenho em outra tarefa relacionada (geralmente mais espec√≠fica e com menos dados dispon√≠veis). [10]

No contexto de LLMs, o processo tipicamente segue estas etapas:

1. **Pr√©-treinamento**: O modelo √© treinado em uma tarefa de modelagem de linguagem em um corpus grande e diversificado.
2. **Transfer√™ncia**: Os pesos aprendidos s√£o transferidos para um novo modelo com arquitetura similar ou id√™ntica.
3. **Adapta√ß√£o**: O novo modelo √© ent√£o ajustado (finetuned) para a tarefa espec√≠fica desejada.

> ‚úîÔ∏è **Destaque**: O sucesso do transfer learning em NLP se deve √† capacidade dos modelos pr√©-treinados de capturar representa√ß√µes lingu√≠sticas ricas e generaliz√°veis.

#### Carregando e Verificando Pesos Pr√©-treinados do Modelo GPT

O processo de carregar pesos pr√©-treinados em um modelo GPT envolve v√°rias etapas t√©cnicas. Vamos examinar um exemplo t√≠pico:

```python
from gpt_download import download_and_load_gpt2
from chapter05 import GPTModel, load_weights_into_gpt

# Configura√ß√£o do modelo
BASE_CONFIG = {
    "vocab_size": 50257,
    "context_length": 1024,
    "emb_dim": 768,
    "n_layers": 12,
    "n_heads": 12,
    "drop_rate": 0.0,
    "qkv_bias": True
}

# Download e carregamento dos pesos
model_size = "124M"
settings, params = download_and_load_gpt2(model_size=model_size, models_dir="gpt2")

# Inicializa√ß√£o do modelo
model = GPTModel(BASE_CONFIG)
load_weights_into_gpt(model, params)
model.eval()
```

Este c√≥digo realiza as seguintes opera√ß√µes cruciais [11]:

1. Define a configura√ß√£o base do modelo, incluindo tamanho do vocabul√°rio, comprimento do contexto, dimens√µes dos embeddings, etc.
2. Baixa os pesos pr√©-treinados do modelo GPT-2.
3. Inicializa uma nova inst√¢ncia do modelo com a configura√ß√£o especificada.
4. Carrega os pesos pr√©-treinados no modelo inicializado.
5. Coloca o modelo em modo de avalia√ß√£o.

> ‚ö†Ô∏è **Nota Importante**: √â crucial garantir que a arquitetura do modelo inicializado seja compat√≠vel com os pesos pr√©-treinados. Discrep√¢ncias podem levar a erros ou comportamentos inesperados.

Para verificar se os pesos foram carregados corretamente, pode-se realizar uma infer√™ncia simples:

```python
from chapter04 import generate_text_simple
from chapter05 import text_to_token_ids, token_ids_to_text

text = "Every effort moves"
token_ids = generate_text_simple(
    model=model,
    idx=text_to_token_ids(text, tokenizer),
    max_new_tokens=15,
    context_size=BASE_CONFIG["context_length"]
)
print(token_ids_to_text(token_ids, tokenizer))
```

Se o modelo gerar texto coerente, √© um bom indicador de que os pesos foram carregados corretamente. [12]

#### Desafios no Uso de Modelos Pr√©-treinados para Tarefas Downstream sem Finetuning

Utilizar modelos pr√©-treinados diretamente para tarefas downstream sem finetuning apresenta v√°rios desafios [13]:

1. **Desalinhamento de Tarefas**: O modelo pr√©-treinado √© otimizado para modelagem de linguagem, n√£o para classifica√ß√£o ou outras tarefas espec√≠ficas.

2. **Vi√©s do Dom√≠nio**: O corpus de pr√©-treinamento pode n√£o representar adequadamente o dom√≠nio da tarefa alvo.

3. **Aus√™ncia de Camada de Sa√≠da Espec√≠fica**: Modelos como GPT n√£o possuem naturalmente uma camada de sa√≠da adequada para classifica√ß√£o.

4. **Overfitting Potencial**: Sem finetuning, o modelo pode se apegar excessivamente a padr√µes do pr√©-treinamento n√£o relevantes para a tarefa alvo.

5. **Inefici√™ncia Computacional**: Usar o modelo completo sem adapta√ß√£o pode ser computacionalmente ineficiente para tarefas simples.

Para ilustrar esses desafios, podemos tentar usar o modelo pr√©-treinado diretamente para classifica√ß√£o:

```python
text = ("Is the following text 'spam'? Answer with 'yes' or 'no':"
        " 'You are a winner you have been specially"
        " selected to receive $1000 cash or a $2000 award.'")
token_ids = generate_text_simple(
    model=model,
    idx=text_to_token_ids(text, tokenizer),
    max_new_tokens=23,
    context_size=BASE_CONFIG["context_length"]
)
print(token_ids_to_text(token_ids, tokenizer))
```

O resultado provavelmente ser√° incoerente ou n√£o relacionado √† tarefa de classifica√ß√£o de spam, demonstrando a necessidade de finetuning. [14]

#### Perguntas T√©cnicas/Te√≥ricas

1. Explique como o princ√≠pio de "catastrophic forgetting" pode afetar o processo de finetuning de um LLM pr√©-treinado. Que estrat√©gias podem ser empregadas para mitigar esse problema?
2. Considere um cen√°rio onde voc√™ tem um LLM pr√©-treinado em textos em ingl√™s e deseja adapt√°-lo para classifica√ß√£o de sentimentos em portugu√™s. Quais desafios espec√≠ficos voc√™ antecipa e como os abordaria?
3. Discuta as implica√ß√µes √©ticas e de vi√©s ao usar modelos pr√©-treinados em grandes corpora de texto da internet para tarefas downstream espec√≠ficas. Como voc√™ avaliaria e mitigaria potenciais vieses?

Certamente. Vamos prosseguir com o pr√≥ximo t√≥pico do nosso resumo aprofundado.

### 6.5 Adicionando uma Cabe√ßa de Classifica√ß√£o

<image: Um diagrama detalhado mostrando a arquitetura de um modelo GPT com uma nova camada de classifica√ß√£o adicionada no topo, destacando as camadas congeladas e as que ser√£o finetuned>

#### Modificando a Arquitetura do LLM Pr√©-treinado para Tarefas de Classifica√ß√£o

A adapta√ß√£o de um LLM pr√©-treinado para uma tarefa de classifica√ß√£o envolve modifica√ß√µes significativas na arquitetura do modelo, principalmente na camada de sa√≠da. Este processo √© crucial para transformar um modelo generativo em um classificador discriminativo. [15]

O processo t√≠pico de modifica√ß√£o inclui:

1. **Remo√ß√£o da Camada de Sa√≠da Original**: A camada final do modelo GPT, que mapeia para o tamanho do vocabul√°rio, √© removida.
2. **Adi√ß√£o de uma Nova Camada de Classifica√ß√£o**: Uma nova camada linear √© adicionada, mapeando as representa√ß√µes ocultas para o n√∫mero de classes desejado.
3. **Ajuste das Dimens√µes**: Garantir que a nova camada de classifica√ß√£o seja compat√≠vel com as dimens√µes das representa√ß√µes ocultas do modelo.

Vamos examinar uma implementa√ß√£o t√≠pica:

```python
import torch

num_classes = 2  # Para classifica√ß√£o bin√°ria (e.g., spam vs. n√£o-spam)
hidden_size = model.out_head.in_features

# Remover a camada de sa√≠da original
del model.out_head

# Adicionar nova camada de classifica√ß√£o
model.out_head = torch.nn.Linear(hidden_size, num_classes)

# Inicializar os pesos da nova camada
torch.nn.init.normal_(model.out_head.weight, std=0.02)
torch.nn.init.zeros_(model.out_head.bias)
```

> ‚úîÔ∏è **Destaque**: A inicializa√ß√£o adequada dos pesos da nova camada √© crucial para um finetuning eficiente. Valores muito grandes ou muito pequenos podem levar a problemas de converg√™ncia.

#### Substitui√ß√£o da Camada de Sa√≠da: De Vocabul√°rio para Classes

A substitui√ß√£o da camada de sa√≠da √© um passo cr√≠tico na adapta√ß√£o do LLM para classifica√ß√£o. Essa mudan√ßa altera fundamentalmente a natureza do modelo [16]:

1. **Camada Original**: 
   - Dimens√µes: `(hidden_size, vocab_size)` (e.g., `(768, 50257)` para GPT-2 pequeno)
   - Fun√ß√£o: Gerar probabilidades para cada token no vocabul√°rio

2. **Nova Camada de Classifica√ß√£o**:
   - Dimens√µes: `(hidden_size, num_classes)` (e.g., `(768, 2)` para classifica√ß√£o bin√°ria)
   - Fun√ß√£o: Gerar logits para cada classe

Esta mudan√ßa pode ser representada matematicamente como:

$$
\text{output} = \text{softmax}(W_{new} \cdot h + b_{new})
$$

Onde:
- $h$ √© o vetor de representa√ß√£o oculta (hidden state)
- $W_{new}$ √© a matriz de pesos da nova camada (dimens√µes: `hidden_size √ó num_classes`)
- $b_{new}$ √© o vetor de bias da nova camada

> ‚ö†Ô∏è **Nota Importante**: Ao substituir a camada de sa√≠da, √© essencial ajustar a fun√ß√£o de perda e as m√©tricas de avalia√ß√£o para refletir a tarefa de classifica√ß√£o, em vez da tarefa de modelagem de linguagem original.

#### T√©cnicas de Congelamento Seletivo de Camadas para Finetuning Eficiente

O congelamento seletivo de camadas √© uma t√©cnica crucial para o finetuning eficiente de LLMs. Esta abordagem permite adaptar o modelo para a nova tarefa enquanto preserva o conhecimento geral adquirido durante o pr√©-treinamento. [17]

Principais considera√ß√µes:

1. **Camadas Inferiores**: Tendem a capturar caracter√≠sticas mais gerais da linguagem.
2. **Camadas Superiores**: Geralmente s√£o mais espec√≠ficas √† tarefa e ao dom√≠nio.

Uma estrat√©gia comum √© congelar as camadas inferiores e permitir o finetuning apenas das camadas superiores e da nova camada de classifica√ß√£o:

```python
# Congelar todas as camadas
for param in model.parameters():
    param.requires_grad = False

# Descongelar as √∫ltimas n camadas
n_layers_to_finetune = 3
for i in range(n_layers_to_finetune):
    for param in model.trf_blocks[-(i+1)].parameters():
        param.requires_grad = True

# Descongelar a camada de classifica√ß√£o
for param in model.out_head.parameters():
    param.requires_grad = True
```

Esta abordagem oferece v√°rias vantagens:
- Reduz o risco de overfitting em datasets pequenos
- Diminui o tempo de treinamento e o uso de mem√≥ria
- Preserva o conhecimento geral adquirido no pr√©-treinamento

> üí° **Dica**: O n√∫mero ideal de camadas a serem finetuned pode variar dependendo do tamanho do dataset e da similaridade entre a tarefa de pr√©-treinamento e a tarefa alvo. Experimente com diferentes configura√ß√µes para otimizar o desempenho.

#### Aten√ß√£o Causal e suas Implica√ß√µes para Tarefas de Classifica√ß√£o

A arquitetura GPT utiliza aten√ß√£o causal, o que significa que cada token s√≥ pode atender a tokens anteriores na sequ√™ncia. Isso apresenta desafios √∫nicos para tarefas de classifica√ß√£o [18]:

1. **Representa√ß√£o Final**: Para classifica√ß√£o, geralmente usamos a representa√ß√£o do √∫ltimo token como entrada para a camada de classifica√ß√£o.

2. **Informa√ß√£o Contextual**: O √∫ltimo token tem acesso a toda a informa√ß√£o da sequ√™ncia, tornando-o ideal para classifica√ß√£o.

3. **Padding e Masking**: √â crucial implementar masking adequado para lidar com sequ√™ncias de comprimento vari√°vel e padding.

A implementa√ß√£o da aten√ß√£o causal pode ser representada matematicamente como:

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V
$$

Onde $M$ √© uma matriz de masking triangular inferior:

$$
M_{ij} = 
\begin{cases} 
0 & \text{se } i \geq j \\
-\infty & \text{caso contr√°rio}
\end{cases}
$$

> ‚ö†Ô∏è **Aten√ß√£o**: Ao adaptar um modelo GPT para classifica√ß√£o, √© importante manter a estrutura de aten√ß√£o causal para preservar a capacidade do modelo de processar sequ√™ncias de forma coerente.

#### Perguntas T√©cnicas/Te√≥ricas

1. Como a escolha do n√∫mero de camadas a serem finetuned afeta o trade-off entre a preserva√ß√£o do conhecimento pr√©-treinado e a adapta√ß√£o √† nova tarefa? Discuta cen√°rios em que voc√™ optaria por finetunear mais ou menos camadas.

2. Explique como a aten√ß√£o causal pode ser tanto uma vantagem quanto uma limita√ß√£o em tarefas de classifica√ß√£o de texto. Como voc√™ poderia adaptar o modelo para mitigar poss√≠veis limita√ß√µes?

3. Considere um cen√°rio onde voc√™ est√° finetuning um LLM para classifica√ß√£o de textos muito longos (por exemplo, artigos cient√≠ficos inteiros). Como voc√™ lidaria com as limita√ß√µes de comprimento de sequ√™ncia do modelo GPT neste caso?

Certamente. Vamos prosseguir com o pr√≥ximo t√≥pico do nosso resumo aprofundado.

### 6.6 Calculando a Loss de Classifica√ß√£o e Acur√°cia

<image: Um diagrama mostrando o fluxo de dados atrav√©s do modelo, culminando na camada de classifica√ß√£o, com visualiza√ß√µes da fun√ß√£o de perda cross-entropy e do c√°lculo de acur√°cia>

#### Cross-Entropy Loss para Classifica√ß√£o Multi-classe

A fun√ß√£o de perda cross-entropy √© fundamental para treinar modelos de classifica√ß√£o, incluindo LLMs finetuned. Esta fun√ß√£o quantifica a diferen√ßa entre a distribui√ß√£o de probabilidade prevista pelo modelo e a distribui√ß√£o real (one-hot encoded) das classes. [19]

Para classifica√ß√£o multi-classe, a cross-entropy loss √© definida como:

$$
L = -\sum_{i=1}^{C} y_i \log(\hat{y}_i)
$$

Onde:
- $C$ √© o n√∫mero de classes
- $y_i$ √© o valor real (0 ou 1) para a classe $i$
- $\hat{y}_i$ √© a probabilidade prevista para a classe $i$

No contexto de finetuning de LLMs para classifica√ß√£o, implementamos esta loss da seguinte forma:

```python
def calc_loss_batch(input_batch, target_batch, model, device):
    input_batch, target_batch = input_batch.to(device), target_batch.to(device)
    logits = model(input_batch)[:, -1, :]  # Logits do √∫ltimo token de sa√≠da
    loss = torch.nn.functional.cross_entropy(logits, target_batch)
    return loss
```

> ‚úîÔ∏è **Destaque**: A fun√ß√£o `cross_entropy` do PyTorch combina o c√°lculo de softmax e log-likelihood, otimizando a performance e estabilidade num√©rica.

#### Ativa√ß√£o Softmax para Distribui√ß√£o de Probabilidade sobre Classes

A fun√ß√£o softmax √© utilizada para converter os logits (sa√≠das brutas da camada de classifica√ß√£o) em uma distribui√ß√£o de probabilidade sobre as classes. Matematicamente, a softmax √© definida como [20]:

$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=1}^C e^{x_j}}
$$

Onde $x_i$ √© o logit para a classe $i$ e $C$ √© o n√∫mero total de classes.

No contexto de nossa implementa√ß√£o:

```python
def get_probabilities(logits):
    return torch.softmax(logits, dim=-1)

# Uso
logits = model(input_batch)[:, -1, :]
probabilities = get_probabilities(logits)
```

A softmax garante que as probabilidades somem 1 e sejam n√£o-negativas, propriedades essenciais para interpreta√ß√£o em classifica√ß√£o.

#### M√©tricas de Acur√°cia de Classifica√ß√£o e seu C√°lculo

A acur√°cia √© uma m√©trica fundamental para avaliar modelos de classifica√ß√£o. Ela representa a propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de previs√µes. [21]

Para classifica√ß√£o bin√°ria ou multi-classe, a acur√°cia √© calculada como:

$$
\text{Acur√°cia} = \frac{\text{N√∫mero de previs√µes corretas}}{\text{N√∫mero total de previs√µes}}
$$

Implementa√ß√£o em PyTorch:

```python
def calc_accuracy_batch(logits, target_batch):
    predicted_labels = torch.argmax(logits, dim=-1)
    correct_predictions = (predicted_labels == target_batch).sum().item()
    return correct_predictions / len(target_batch)

# Uso
logits = model(input_batch)[:, -1, :]
accuracy = calc_accuracy_batch(logits, target_batch)
```

> ‚ö†Ô∏è **Nota Importante**: Embora a acur√°cia seja intuitiva, ela pode ser enganosa em datasets desbalanceados. Considere m√©tricas adicionais como precis√£o, recall e F1-score para uma avalia√ß√£o mais completa.

#### T√©cnicas de Avalia√ß√£o de Performance por Batch e por Dataset

A avalia√ß√£o de performance do modelo pode ser feita tanto por batch quanto por dataset completo. Cada abordagem tem suas vantagens [22]:

1. **Avalia√ß√£o por Batch**:
   - Mais r√°pida e eficiente em mem√≥ria
   - √ötil para monitoramento durante o treinamento
   - Pode ser vol√°til devido √† variabilidade entre batches

2. **Avalia√ß√£o por Dataset**:
   - Fornece uma vis√£o mais est√°vel e abrangente do desempenho
   - Mais custosa computacionalmente
   - Essencial para avalia√ß√£o final e compara√ß√£o de modelos

Implementa√ß√£o de avalia√ß√£o por dataset:

```python
def calc_accuracy_loader(data_loader, model, device):
    model.eval()
    correct_predictions, num_examples = 0, 0
    
    with torch.no_grad():
        for input_batch, target_batch in data_loader:
            input_batch, target_batch = input_batch.to(device), target_batch.to(device)
            logits = model(input_batch)[:, -1, :]
            predicted_labels = torch.argmax(logits, dim=-1)
            correct_predictions += (predicted_labels == target_batch).sum().item()
            num_examples += target_batch.size(0)
    
    return correct_predictions / num_examples
```

> üí° **Dica**: Durante o treinamento, alterne entre avalia√ß√µes r√°pidas por batch e avalia√ß√µes peri√≥dicas mais completas por dataset para balancear efici√™ncia e confiabilidade.

#### Perguntas T√©cnicas/Te√≥ricas

1. Em um cen√°rio de classifica√ß√£o multi-classe altamente desbalanceado, como a cross-entropy loss pode ser problem√°tica? Proponha e explique uma modifica√ß√£o na fun√ß√£o de perda para lidar com este desbalanceamento.

2. Discuta as vantagens e desvantagens de usar a representa√ß√£o do √∫ltimo token versus uma representa√ß√£o agregada (como m√©dia ou max pooling) de todos os tokens para classifica√ß√£o em um modelo baseado em GPT. Como essa escolha pode afetar o desempenho em diferentes tipos de tarefas de classifica√ß√£o?

3. Explique como voc√™ implementaria uma t√©cnica de early stopping baseada na acur√°cia de valida√ß√£o durante o finetuning de um LLM. Que considera√ß√µes adicionais voc√™ teria ao aplicar early stopping em um modelo grande com muitos par√¢metros?

Certamente. Vamos prosseguir com o √∫ltimo t√≥pico do nosso resumo aprofundado.

### 6.7 Finetuning do Modelo em Dados Supervisionados

<image: Um diagrama de fluxo mostrando o processo iterativo de finetuning, incluindo forward pass, c√°lculo de loss, backpropagation, e atualiza√ß√£o de pesos, com gr√°ficos mostrando a evolu√ß√£o da loss e acur√°cia ao longo das √©pocas>

#### Algoritmos de Otimiza√ß√£o para Finetuning: AdamW e Weight Decay

O finetuning eficiente de LLMs requer algoritmos de otimiza√ß√£o robustos. O AdamW (Adam com Weight Decay desacoplado) √© uma escolha popular devido √† sua efic√°cia em lidar com problemas de otimiza√ß√£o n√£o-convexos e sua capacidade de adaptar as taxas de aprendizado para cada par√¢metro. [23]

A atualiza√ß√£o de par√¢metros no AdamW √© dada por:

$$
\begin{aligned}
m_t &= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
v_t &= \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \\
\hat{m}_t &= \frac{m_t}{1 - \beta_1^t} \\
\hat{v}_t &= \frac{v_t}{1 - \beta_2^t} \\
\theta_t &= \theta_{t-1} - \alpha \left(\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} + \lambda \theta_{t-1}\right)
\end{aligned}
$$

Onde:
- $m_t$, $v_t$ s√£o as estimativas do primeiro e segundo momento
- $\beta_1$, $\beta_2$ s√£o os fatores de decaimento para os momentos
- $\alpha$ √© a taxa de aprendizado
- $\lambda$ √© o fator de weight decay
- $g_t$ √© o gradiente no tempo $t$

Implementa√ß√£o em PyTorch:

```python
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
```

> ‚úîÔ∏è **Destaque**: O weight decay desacoplado no AdamW ajuda a prevenir overfitting, especialmente importante no finetuning de modelos grandes com datasets relativamente pequenos.

#### Estrat√©gias de Sele√ß√£o de Learning Rate para Finetuning

A escolha da learning rate (taxa de aprendizado) √© crucial para o sucesso do finetuning. Algumas estrat√©gias comuns incluem [24]:

1. **Learning Rate Constante**: Simples, mas pode ser sub√≥tima.
2. **Learning Rate Decay**: Diminui a LR ao longo do tempo, permitindo converg√™ncia fina.
3. **Cyclical Learning Rates**: Alterna entre valores altos e baixos, potencialmente escapando de m√≠nimos locais.
4. **Learning Rate Warmup**: Come√ßa com uma LR baixa e aumenta gradualmente, estabilizando o treinamento inicial.

Uma abordagem eficaz √© o uso de learning rate warmup seguido de decay:

```python
from transformers import get_linear_schedule_with_warmup

num_training_steps = len(train_loader) * num_epochs
num_warmup_steps = int(0.1 * num_training_steps)

scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=num_warmup_steps,
    num_training_steps=num_training_steps
)
```

> üí° **Dica**: Experimente com diferentes schedulers e par√¢metros para encontrar a configura√ß√£o ideal para seu caso espec√≠fico.

#### Loops de Treinamento Baseados em √âpocas e Crit√©rios de Early Stopping

O treinamento baseado em √©pocas envolve iterar sobre todo o dataset m√∫ltiplas vezes. Um loop de treinamento t√≠pico para finetuning inclui [25]:

```python
def train_model(model, train_loader, val_loader, optimizer, scheduler, num_epochs, device):
    best_val_loss = float('inf')
    patience = 3
    patience_counter = 0

    for epoch in range(num_epochs):
        model.train()
        for batch in train_loader:
            optimizer.zero_grad()
            input_ids, labels = batch
            input_ids, labels = input_ids.to(device), labels.to(device)
            
            outputs = model(input_ids)
            loss = criterion(outputs.logits, labels)
            
            loss.backward()
            optimizer.step()
            scheduler.step()
        
        val_loss = evaluate_model(model, val_loader, device)
        print(f"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}")
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print("Early stopping triggered")
                break
```

Early stopping √© uma t√©cnica crucial para prevenir overfitting, parando o treinamento quando o desempenho no conjunto de valida√ß√£o para de melhorar.

> ‚ö†Ô∏è **Nota Importante**: Ajuste o crit√©rio de early stopping (por exemplo, paci√™ncia) com base no tamanho e complexidade do seu modelo e dataset.

#### Monitoramento de M√©tricas de Treinamento e Valida√ß√£o para Detectar Overfitting

O monitoramento cont√≠nuo das m√©tricas de treinamento e valida√ß√£o √© essencial para detectar overfitting e ajustar o processo de finetuning [26]. M√©tricas importantes incluem:

1. **Loss de Treinamento e Valida√ß√£o**: Diverg√™ncia entre estas curvas indica overfitting.
2. **Acur√°cia de Treinamento e Valida√ß√£o**: Similar √† loss, mas mais interpret√°vel.
3. **Gradientes**: Normas de gradiente muito altas ou baixas podem indicar problemas.

Implementa√ß√£o de um logger b√°sico:

```python
class TrainingLogger:
    def __init__(self):
        self.train_losses = []
        self.val_losses = []
        self.train_accuracies = []
        self.val_accuracies = []

    def log(self, train_loss, val_loss, train_acc, val_acc):
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.train_accuracies.append(train_acc)
        self.val_accuracies.append(val_acc)

    def plot_metrics(self):
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(self.train_losses, label='Train Loss')
        plt.plot(self.val_losses, label='Val Loss')
        plt.legend()
        plt.title('Loss over Epochs')
        
        plt.subplot(1, 2, 2)
        plt.plot(self.train_accuracies, label='Train Acc')
        plt.plot(self.val_accuracies, label='Val Acc')
        plt.legend()
        plt.title('Accuracy over Epochs')
        
        plt.tight_layout()
        plt.show()
```

> üí° **Dica**: Utilize ferramentas como TensorBoard ou Weights & Biases para visualiza√ß√£o e monitoramento mais avan√ßados durante o finetuning.

#### Perguntas T√©cnicas/Te√≥ricas

1. Compare e contraste as vantagens e desvantagens de usar AdamW versus SGD com momentum para finetuning de LLMs. Em quais cen√°rios voc√™ preferiria um sobre o outro?

2. Discuta as implica√ß√µes de usar uma learning rate muito alta versus muito baixa durante o finetuning de um LLM. Como voc√™ determinaria a learning rate "ideal" para um projeto espec√≠fico?

3. Proponha e explique uma estrat√©gia para lidar com o problema de "catastrophic forgetting" durante o finetuning de um LLM para uma tarefa espec√≠fica, mantendo sua capacidade de generaliza√ß√£o em outras tarefas.

### Perguntas Avan√ßadas

1. Considere um cen√°rio onde voc√™ est√° finetuning um LLM para uma tarefa de classifica√ß√£o multi-r√≥tulo com um grande n√∫mero de classes poss√≠veis (por exemplo, mais de 1000). Como voc√™ adaptaria a arquitetura do modelo e as t√©cnicas de treinamento para lidar eficientemente com este cen√°rio? Discuta poss√≠veis trade-offs e otimiza√ß√µes.

2. Explique como voc√™ implementaria um sistema de finetuning cont√≠nuo para um LLM em produ√ß√£o, que se adapta a novos dados e tarefas ao longo do tempo sem perder o desempenho em tarefas anteriores. Quais desafios t√©cnicos e pr√°ticos voc√™ antecipa e como os abordaria?

3. Discuta as implica√ß√µes √©ticas e de vi√©s ao finetunear LLMs para tarefas de classifica√ß√£o em dom√≠nios sens√≠veis (por exemplo, an√°lise de sentimentos em contextos pol√≠ticos ou detec√ß√£o de discurso de √≥dio). Como voc√™ garantiria a robustez e fairness do modelo finetuned?

4. Proponha uma abordagem para combinar finetuning de modelo e aprendizado federado em um cen√°rio onde os dados de treinamento s√£o sens√≠veis e distribu√≠dos entre m√∫ltiplos clientes. Quais desafios t√©cnicos voc√™ enfrentaria e como os resolveria?

5. Compare e contraste as abordagens de finetuning de LLMs com t√©cnicas mais recentes como Prompt Engineering e In-Context Learning. Em quais cen√°rios cada abordagem seria mais apropriada, e como voc√™ poderia combinar essas t√©cnicas para otimizar o desempenho em tarefas de classifica√ß√£o complexas?

### Conclus√£o

O finetuning de Large Language Models para tarefas de classifica√ß√£o √© um processo complexo que envolve considera√ß√µes cuidadosas em v√°rias etapas, desde a prepara√ß√£o dos dados at√© a otimiza√ß√£o e avalia√ß√£o do modelo. As t√©cnicas discutidas neste resumo, incluindo a modifica√ß√£o da arquitetura do modelo, estrat√©gias de otimiza√ß√£o e monitoramento de performance, s√£o cruciais para adaptar efetivamente LLMs pr√©-treinados para tarefas espec√≠ficas de classifica√ß√£o.

A compreens√£o profunda desses conceitos e t√©cnicas permite aos praticantes de NLP e Machine Learning aproveitar o poder dos LLMs de forma eficiente, adaptando-os para uma variedade de aplica√ß√µes pr√°ticas. √Ä medida que o campo continua a evoluir, √© essencial manter-se atualizado com as √∫ltimas pesquisas e melhores pr√°ticas, sempre considerando as implica√ß√µes √©ticas e pr√°ticas do uso de modelos de linguagem poderosos em aplica√ß√µes do mundo real.

### Refer√™ncias

[1] "Finetuning de Large Language Models (LLMs) para tarefas espec√≠ficas tem se tornado uma pr√°tica essencial no campo do Processamento de Linguagem Natural (NLP)." (Trecho do in√≠cio do cap√≠tulo)

[2] "Finetuning: Processo de ajuste fino de um modelo pr√©-treinado para uma tarefa espec√≠fica, mantendo a maior parte dos pesos originais." (Trecho da tabela de Conceitos Fundamentais)

[3] "Transfer Learning: T√©cnica que utiliza conhecimento adquirido em uma tarefa para melhorar o desempenho em outra tarefa relacionada." (Trecho da tabela de Conceitos Fundamentais)

[4] "Classifica√ß√£o de Texto: Tarefa de atribuir uma ou mais categorias predefinidas a um texto de entrada, baseando-se em seu conte√∫do." (Trecho da tabela de Conceitos Fundamentais)

[5] "Ao trabalhar com textos de comprimento vari√°vel em tarefas de classifica√ß√£o, dois principais desafios surgem: a necessidade de processar entradas em lotes (batches) e a limita√ß√£o do modelo em lidar com sequ√™ncias de comprimento fixo." (Trecho da se√ß√£o 6.3)

[6] "No contexto do finetuning de LLMs para classifica√ß√£o, a abordagem de padding √© frequentemente preferida, pois preserva informa√ß√µes potencialmente cruciais para a tarefa de classifica√ß√£o." (Trecho da se√ß√£o 6.3)

[7] "Esta implementa√ß√£o da classe `SpamDataset` realiza v√°rias opera√ß√µes cruciais" (Trecho da se√ß√£o 6.3)

[8] "O `DataLoader` oferece v√°rias vantagens" (Trecho da se√ß√£o 6.3)

[9] "Ao trabalhar com sequ√™ncias padded, √© crucial implementar attention masking para evitar que o modelo atenda a tokens de padding." (Trecho da se√ß√£o 6.3)

[10] "Transfer Learning √© uma t√©cnica fundamental no campo de NLP, especialmente quando se trabalha com Large Language Models." (Trecho da se√ß√£o 6.4)

[11] "Este c√≥digo realiza as seguintes opera√ß√µes cruciais" (Trecho da se√ß√£o 6.4)

[12] "Se o modelo gerar texto coerente, √© um bom indicador de que os pesos foram carregados corretamente." (Trecho da se√ß√£o 6.4)

[13] "Utilizar modelos pr√©-treinados diretamente para tarefas downstream sem finetuning apresenta v√°rios desafios" (Trecho da se√ß√£o 6.4)

[14] "O resultado provavelmente ser√° incoerente ou n√£o relacionado √† tarefa de classifica√ß√£o de spam, demonstrando a necessidade de finetuning." (Trecho da se√ß√£o 6.4)

[15] "A adapta√ß√£o de um LLM pr√©-treinado para uma tarefa de classifica√ß√£o envolve modifica√ß√µes significativas na arquitetura do modelo, principalmente na camada de sa√≠da." (Trecho da se√ß√£o 6.5)

[16] "A substitui√ß√£o da camada de sa√≠da √© um passo cr√≠tico na adapta√ß√£o do LLM para classifica√ß√£o. Essa mudan√ßa altera fundamentalmente a natureza do modelo" (Trecho da se√ß√£o 6.5)

[17] "O congelamento seletivo de camadas √© uma t√©cnica crucial para o finetuning eficiente de LLMs." (Trecho da se√ß√£o 6.5)

[18] "A arquitetura GPT utiliza aten√ß√£o causal, o que significa que cada token s√≥ pode atender a tokens anteriores na sequ√™ncia. Isso apresenta desafios √∫nicos para tarefas de classifica√ß√£o" (Trecho da se√ß√£o 6.5)

[19] "A fun√ß√£o de perda cross-entropy √© fundamental para treinar modelos de classifica√ß√£o, incluindo LLMs finetuned." (Trecho da se√ß√£o 6.6)

[20] "A fun√ß√£o softmax √© utilizada para converter os logits (sa√≠das brutas da camada de classifica√ß√£o) em uma distribui√ß√£o de probabilidade sobre as classes." (Trecho da se√ß√£o 6.6)

[21] "A acur√°cia √© uma m√©trica fundamental para avaliar modelos de classifica√ß√£o. Ela representa a propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de previs√µes." (Trecho da se√ß√£o 6.6)

[22] "A avalia√ß√£o de performance do modelo pode ser feita tanto por batch quanto por dataset completo. Cada abordagem tem suas vantagens" (Trecho da se√ß√£o 6.6)

[23] "O finetuning eficiente de LLMs requer algoritmos de otimiza√ß√£o robustos. O AdamW (Adam com Weight Decay desacoplado) √© uma escolha popular devido √† sua efic√°cia em lidar com problemas de otimiza√ß√£o n√£o-convexos e sua capacidade de adaptar as taxas de aprendizado para cada par√¢metro." (Trecho da se√ß√£o 6.7)

[24] "A escolha da learning rate (taxa de